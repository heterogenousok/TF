{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport sklearn\nimport pandas as pd\nimport os\nimport sys\nimport time\nimport tensorflow as tf\n\nfrom tensorflow import keras\n\nprint(tf.__version__)\nprint(sys.version_info)\nfor module in mpl, np, pd, sklearn, tf, keras:\n    print(module.__name__, module.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:31:12.093725Z","iopub.execute_input":"2021-08-02T06:31:12.094123Z","iopub.status.idle":"2021-08-02T06:31:19.027210Z","shell.execute_reply.started":"2021-08-02T06:31:12.094084Z","shell.execute_reply":"2021-08-02T06:31:19.026009Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2.4.1\nsys.version_info(major=3, minor=7, micro=10, releaselevel='final', serial=0)\nmatplotlib 3.4.1\nnumpy 1.19.5\npandas 1.1.5\nsklearn 0.24.1\ntensorflow 2.4.1\ntensorflow.keras 2.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:31:19.032804Z","iopub.execute_input":"2021-08-02T06:31:19.035754Z","iopub.status.idle":"2021-08-02T06:31:19.889737Z","shell.execute_reply.started":"2021-08-02T06:31:19.035700Z","shell.execute_reply":"2021-08-02T06:31:19.888515Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Mon Aug  2 06:31:19 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   43C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1. loads data\n# 2. preprocesses data -> dataset\n# 3. tools\n# 3.1 generates position embedding\n# 3.2 create mask. (a. padding, b. decoder)\n# 3.3 scaled_dot_product_attention\n# 4. builds model 分为以下6步\n    # 4.1 MultiheadAttention\n    # 4.2 EncoderLayer\n    # 4.3 DecoderLayer\n    # 4.4 EncoderModel\n    # 4.5 DecoderModel\n    # 4.6 Transformer\n# 5. optimizer & loss\n# 6. train step -> train\n# 7. Evaluate and Visualize","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:31:19.893895Z","iopub.execute_input":"2021-08-02T06:31:19.894223Z","iopub.status.idle":"2021-08-02T06:31:19.900977Z","shell.execute_reply.started":"2021-08-02T06:31:19.894177Z","shell.execute_reply":"2021-08-02T06:31:19.899081Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\n#葡萄牙语到英语，这个是基于subword的\nexamples, info = tfds.load('ted_hrlr_translate/pt_to_en',\n                           with_info = True,\n                           as_supervised = True)\n\ntrain_examples, val_examples = examples['train'], examples['validation']\nprint(info)#info里是数据集的描述","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:31:19.903670Z","iopub.execute_input":"2021-08-02T06:31:19.904185Z","iopub.status.idle":"2021-08-02T06:31:51.824369Z","shell.execute_reply.started":"2021-08-02T06:31:19.904137Z","shell.execute_reply":"2021-08-02T06:31:51.822888Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[1mDownloading and preparing dataset ted_hrlr_translate/pt_to_en/1.0.0 (download: 124.94 MiB, generated: Unknown size, total: 124.94 MiB) to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6b3af2a6294c388ef74c3a7da04e77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b495758d2f54e7abe702009a75622d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extraction completed...: 0 file [00:00, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"682f5fe4738f48efb6107981853d20ba"}},"metadata":{}},{"name":"stdout","text":"\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Shuffling and writing examples to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteGFYFA3/ted_hrlr_translate-train.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/51785 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d24139b09eaa4bcebeb03d3218dc375c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Shuffling and writing examples to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteGFYFA3/ted_hrlr_translate-validation.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1193 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c431f292aea24c1aa02a103c7c2a2dd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Shuffling and writing examples to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteGFYFA3/ted_hrlr_translate-test.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1803 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74447f3e35744c81b0e789e0800e86ea"}},"metadata":{}},{"name":"stdout","text":"\u001b[1mDataset ted_hrlr_translate downloaded and prepared to /root/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0. Subsequent calls will reuse this data.\u001b[0m\ntfds.core.DatasetInfo(\n    name='ted_hrlr_translate',\n    version=1.0.0,\n    description='Data sets derived from TED talk transcripts for comparing similar language pairs\nwhere one is high resource and the other is low resource.',\n    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n    features=Translation({\n        'en': Text(shape=(), dtype=tf.string),\n        'pt': Text(shape=(), dtype=tf.string),\n    }),\n    total_num_examples=54781,\n    splits={\n        'test': 1803,\n        'train': 51785,\n        'validation': 1193,\n    },\n    supervised_keys=('pt', 'en'),\n    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n      booktitle = {HLT-NAACL},\n      year    = {2018},\n      }\"\"\",\n    redistribution_info=,\n)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#葡萄牙语中有一些特除的字符，用转义字符来打印\nfor pt, en in train_examples.take(5):\n    print(pt.numpy())\n    print(en.numpy())\n    print()\nprint(train_examples)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:31:51.826294Z","iopub.execute_input":"2021-08-02T06:31:51.827248Z","iopub.status.idle":"2021-08-02T06:31:51.991074Z","shell.execute_reply.started":"2021-08-02T06:31:51.827165Z","shell.execute_reply":"2021-08-02T06:31:51.989756Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"b'e quando melhoramos a procura , tiramos a \\xc3\\xbanica vantagem da impress\\xc3\\xa3o , que \\xc3\\xa9 a serendipidade .'\nb'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .'\n\nb'mas e se estes fatores fossem ativos ?'\nb'but what if it were active ?'\n\nb'mas eles n\\xc3\\xa3o tinham a curiosidade de me testar .'\nb\"but they did n't test for curiosity .\"\n\nb'e esta rebeldia consciente \\xc3\\xa9 a raz\\xc3\\xa3o pela qual eu , como agn\\xc3\\xb3stica , posso ainda ter f\\xc3\\xa9 .'\nb'and this conscious defiance is why i , as an agnostic , can still have faith .'\n\nb\"`` `` '' podem usar tudo sobre a mesa no meu corpo . ''\"\nb'you can use everything on the table on me .'\n\n<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>\n","output_type":"stream"}]},{"cell_type":"code","source":"#这里运行要点时间\n#我们自己转为subword数据集，2**13是8192，build_from_corpus\n#在2.5版本中已经弃用，换用maybe_build_from_corpus\nen_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n    (en.numpy() for pt, en in train_examples),\n    target_vocab_size = 2 ** 13)\npt_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n    (pt.numpy() for pt, en in train_examples),\n    target_vocab_size = 2 ** 13)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:31:51.993471Z","iopub.execute_input":"2021-08-02T06:31:51.993811Z","iopub.status.idle":"2021-08-02T06:35:39.730351Z","shell.execute_reply.started":"2021-08-02T06:31:51.993778Z","shell.execute_reply":"2021-08-02T06:35:39.729105Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#测试一个字符串,subword里边是包含空格的\nsample_string = \"Transformer is awesome.\"\n\ntokenized_string = en_tokenizer.encode(sample_string)\n#tokenized_string编码后的id列表\nprint('Tokenized string is {}'.format(tokenized_string))  \n\norigin_string = en_tokenizer.decode(tokenized_string)\n#decode会自动将一个id的列表，变为原字符串\nprint('The original string is {}'.format(origin_string))\n\nassert origin_string == sample_string\n\nfor token in tokenized_string:\n    print('{} --> \"{}\"-->{}'.format(token, en_tokenizer.decode([token]),len(en_tokenizer.decode([token]))))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:35:39.732041Z","iopub.execute_input":"2021-08-02T06:35:39.732492Z","iopub.status.idle":"2021-08-02T06:35:39.745655Z","shell.execute_reply.started":"2021-08-02T06:35:39.732433Z","shell.execute_reply":"2021-08-02T06:35:39.744027Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\nThe original string is Transformer is awesome.\n7915 --> \"T\"-->1\n1248 --> \"ran\"-->3\n7946 --> \"s\"-->1\n7194 --> \"former \"-->7\n13 --> \"is \"-->3\n2799 --> \"awesome\"-->7\n7877 --> \".\"-->1\n","output_type":"stream"}]},{"cell_type":"code","source":"pt_tokenizer.vocab_size  #词典的大小并不是刚好等于8192","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:35:39.750523Z","iopub.execute_input":"2021-08-02T06:35:39.751036Z","iopub.status.idle":"2021-08-02T06:35:39.761710Z","shell.execute_reply.started":"2021-08-02T06:35:39.750986Z","shell.execute_reply":"2021-08-02T06:35:39.760225Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"8214"},"metadata":{}}]},{"cell_type":"code","source":"en_tokenizer.vocab_size","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:35:39.764724Z","iopub.execute_input":"2021-08-02T06:35:39.765207Z","iopub.status.idle":"2021-08-02T06:35:39.775909Z","shell.execute_reply.started":"2021-08-02T06:35:39.765157Z","shell.execute_reply":"2021-08-02T06:35:39.774695Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"8087"},"metadata":{}}]},{"cell_type":"code","source":"buffer_size = 20000\nbatch_size = 64\nmax_length = 40  #输入和输出的最大长度是40\n\n#把两段文本转为subword形式，[pt_tokenizer.vocab_size]和[pt_tokenizer.vocab_size + 1]\n#分别代表一句话开始标记和结束标记\ndef encode_to_subword(pt_sentence, en_sentence):\n    pt_sequence = [pt_tokenizer.vocab_size] \\\n    + pt_tokenizer.encode(pt_sentence.numpy()) \\\n    + [pt_tokenizer.vocab_size + 1]\n    en_sequence = [en_tokenizer.vocab_size] \\\n    + en_tokenizer.encode(en_sentence.numpy()) \\\n    + [en_tokenizer.vocab_size + 1]\n    return pt_sequence, en_sequence\n\n#用tf的API消去大于最大长度的,只要葡萄牙语和英语同时小于等于40的样本\ndef filter_by_max_length(pt, en):\n    return tf.logical_and(tf.size(pt) <= max_length,\n                          tf.size(en) <= max_length)\n#用py_function封装一下encode_to_subword\ndef tf_encode_to_subword(pt_sentence, en_sentence):\n    return tf.py_function(encode_to_subword,\n                          [pt_sentence, en_sentence],\n                          [tf.int64, tf.int64])\n#把所有句子变为subword，subword都变为id\ntrain_dataset = train_examples.map(tf_encode_to_subword)\ntrain_dataset = train_dataset.filter(filter_by_max_length)\n#接着做洗牌，padding，batch -1，-1代表两个维度，每个维度都在当前维度下扩展到最高的值\ntrain_dataset = train_dataset.shuffle(\n    buffer_size).padded_batch(\n    batch_size, padded_shapes=([-1], [-1]))\n\nvalid_dataset = val_examples.map(tf_encode_to_subword)\nvalid_dataset = valid_dataset.filter(\n    filter_by_max_length).padded_batch(\n    batch_size, padded_shapes=([-1], [-1]))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:35:39.777255Z","iopub.execute_input":"2021-08-02T06:35:39.777785Z","iopub.status.idle":"2021-08-02T06:35:39.924108Z","shell.execute_reply.started":"2021-08-02T06:35:39.777736Z","shell.execute_reply":"2021-08-02T06:35:39.922954Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"x = tf.constant([1, 2, 3, 4])\ny = tf.constant([1, 2, 3, 4])\ntf.math.logical_and(tf.size(x)<=4,tf.size(y)<=4)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:35:39.925654Z","iopub.execute_input":"2021-08-02T06:35:39.926164Z","iopub.status.idle":"2021-08-02T06:35:40.271115Z","shell.execute_reply.started":"2021-08-02T06:35:39.926107Z","shell.execute_reply":"2021-08-02T06:35:40.269571Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(), dtype=bool, numpy=True>"},"metadata":{}}]},{"cell_type":"code","source":"for pt_batch, en_batch in train_dataset.take(5):\n    print(pt_batch.shape, en_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:35:40.276665Z","iopub.execute_input":"2021-08-02T06:35:40.277217Z","iopub.status.idle":"2021-08-02T06:35:58.930045Z","shell.execute_reply.started":"2021-08-02T06:35:40.277154Z","shell.execute_reply":"2021-08-02T06:35:58.928849Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(64, 38) (64, 40)\n(64, 40) (64, 38)\n(64, 40) (64, 39)\n(64, 39) (64, 38)\n(64, 40) (64, 37)\n","output_type":"stream"}]},{"cell_type":"code","source":"for pt_batch, en_batch in train_dataset.take(1):\n    print(pt_batch[0], en_batch[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:35:58.932201Z","iopub.execute_input":"2021-08-02T06:35:58.932920Z","iopub.status.idle":"2021-08-02T06:36:16.129934Z","shell.execute_reply.started":"2021-08-02T06:35:58.932868Z","shell.execute_reply":"2021-08-02T06:36:16.128802Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[8214   27 1417 8003   38    4   44  955    4 6255    7 1070 1086  184\n 1174 1803 1461  898  403   12  266 1772    1   31  115 2652    6    4\n   75    9 3939    1   40   56 5943    2 8215    0    0], shape=(39,), dtype=int64) tf.Tensor(\n[8087   12  466  183  180    5  609 6943  246 7475   26  487   32  991\n  158   11  432    8 4974    9    4 2134   32 1383    1  158   59   10\n   20    7 7207    2 8088    0    0    0    0    0    0], shape=(39,), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"np.arange(50)[:, np.newaxis]","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.133622Z","iopub.execute_input":"2021-08-02T06:36:16.133956Z","iopub.status.idle":"2021-08-02T06:36:16.141844Z","shell.execute_reply.started":"2021-08-02T06:36:16.133921Z","shell.execute_reply":"2021-08-02T06:36:16.140596Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[ 0],\n       [ 1],\n       [ 2],\n       [ 3],\n       [ 4],\n       [ 5],\n       [ 6],\n       [ 7],\n       [ 8],\n       [ 9],\n       [10],\n       [11],\n       [12],\n       [13],\n       [14],\n       [15],\n       [16],\n       [17],\n       [18],\n       [19],\n       [20],\n       [21],\n       [22],\n       [23],\n       [24],\n       [25],\n       [26],\n       [27],\n       [28],\n       [29],\n       [30],\n       [31],\n       [32],\n       [33],\n       [34],\n       [35],\n       [36],\n       [37],\n       [38],\n       [39],\n       [40],\n       [41],\n       [42],\n       [43],\n       [44],\n       [45],\n       [46],\n       [47],\n       [48],\n       [49]])"},"metadata":{}}]},{"cell_type":"code","source":"np.arange(512)[np.newaxis, :]","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.143606Z","iopub.execute_input":"2021-08-02T06:36:16.144428Z","iopub.status.idle":"2021-08-02T06:36:16.159386Z","shell.execute_reply.started":"2021-08-02T06:36:16.144376Z","shell.execute_reply":"2021-08-02T06:36:16.157835Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n        416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n        442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n        455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n        481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n        494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n        507, 508, 509, 510, 511]])"},"metadata":{}}]},{"cell_type":"code","source":"#第三步，写一些工具函数\n# PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))\n# PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n\n#pos 和i都是矩阵\n# pos.shape: [sentence_length, 1]\n# i.shape  : [1, d_model]\n# result.shape: [sentence_length, d_model]\ndef get_angles(pos, i, d_model):\n    angle_rates = 1 / np.power(10000,\n                               (2 * (i // 2)) / np.float32(d_model))\n    return pos * angle_rates\n\n#计算位置信息\ndef get_position_embedding(sentence_length, d_model):\n    #sentence_length和d_model都扩展为矩阵\n#     print(np.arange(sentence_length)[:, np.newaxis])\n#     print(np.arange(d_model)[np.newaxis, :])\n    #pos是0到49，就是词的位置，i是从0到511，总计512，和dim相等\n    angle_rads = get_angles(np.arange(sentence_length)[:, np.newaxis],\n                            np.arange(d_model)[np.newaxis, :],\n                            d_model)\n    print(angle_rads.shape)\n    # sines.shape: [sentence_length, d_model / 2]\n    # cosines.shape: [sentence_length, d_model / 2]\n    print(angle_rads[:, 0::2].shape)\n    print(angle_rads[:, 1::2].shape)\n    sines = np.sin(angle_rads[:, 0::2])\n    cosines = np.cos(angle_rads[:, 1::2])\n    \n    #把sines和cosines进行拼接\n    # position_embedding.shape: [sentence_length, d_model]\n    position_embedding = np.concatenate([sines, cosines], axis = -1)\n    #进行维度扩展\n    print(position_embedding.shape)\n    # position_embedding.shape: [1, sentence_length, d_model]\n    position_embedding = position_embedding[np.newaxis, ...]\n    #变为float32类型\n    return tf.cast(position_embedding, dtype=tf.float32)\n\nposition_embedding = get_position_embedding(50, 512)\nprint(position_embedding.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.161352Z","iopub.execute_input":"2021-08-02T06:36:16.162032Z","iopub.status.idle":"2021-08-02T06:36:16.187023Z","shell.execute_reply.started":"2021-08-02T06:36:16.161984Z","shell.execute_reply":"2021-08-02T06:36:16.185778Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(50, 512)\n(50, 256)\n(50, 256)\n(50, 512)\n(1, 50, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"#这个图和我们原理中展示的横纵坐标是颠倒的\ndef plot_position_embedding(position_embedding):\n    plt.pcolormesh(position_embedding[0], cmap = 'RdBu')\n    plt.xlabel('Depth')\n    plt.xlim((0, 512))\n    plt.ylabel('Position')\n    plt.colorbar()\n    plt.show()\n    \nplot_position_embedding(position_embedding)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.190474Z","iopub.execute_input":"2021-08-02T06:36:16.190978Z","iopub.status.idle":"2021-08-02T06:36:16.542500Z","shell.execute_reply.started":"2021-08-02T06:36:16.190927Z","shell.execute_reply":"2021-08-02T06:36:16.541463Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABioklEQVR4nO2deZgU1dm376eq19n3GZgBBhgQEEERcMEd97glcY9Ro8Ykb0xiYhaXJL7JZxLN4vImGkMSozHGfUPF4AbiEhFU9l3WYfZ96b37fH9UddMzzDANzAAD576uc3XVqaquqqE5Xf07z/N7RCmFRqPRaA4NjP19ARqNRqPZd+hBX6PRaA4h9KCv0Wg0hxB60NdoNJpDCD3oazQazSGEHvQ1Go3mEGJAB30R2Swiy0VkiYgstvvyRORNEVlvv+YO5DVoNBrN/kJEHhGROhFZ0ct2EZH/E5ENIrJMRKYkbbvGHifXi8g1/XVN++JJ/1Sl1JFKqan2+q3A20qpMcDb9rpGo9EcjDwKnL2L7ecAY+x2I/BnsB6OgTuBY4DpwJ399YC8P+SdC4HH7OXHgIv2wzVoNBrNgKOUWgA07WKXC4F/KouPgBwRGQKcBbyplGpSSjUDb7LrL4+UcfTHm+wCBbwhIgr4i1JqFlCslKq2t9cAxT0dKCI3Yn3zkZ7mPXrsuPFINExDEBwb1hMbM4aoUgTXrKNzaDnpXgeycQNlE0by6aYmhg8vwdywnrZIjGEVxazt9OBvbWH48BKy22qoqWolzTTIGzOUBtKprm0lEgogIniyshiWl0YGQQI1NXQ2B/BFYyjAbQhpHgfubC8OjwsjI4eI6aYzHKUjGKUjECYSihGNhIlFwqhoBKViEM98FgEEMQxEDMQ07VcHYgiGIQAYhiTWTUMwpNurAQaCCIgIAhhJyyIg8e1YzTq/1Z+0mvQ37/Zv0OvKTqt99u/xnrvYrfLTFTR4M8n3t9OcmcdhDh/ukRUsW1/NkcMyadtYySZPPuWlubStXEPZhBEs3dZORm4OZb5q6hv85KQ5MUaPYf3mGsR0MmZYPo66bdTVtWMi5BdnYA4ZztZmPz5/hGBHG6gYzrQsMjPdFGe68aoQkZZGAs2d+P1hglFFDOvDbwq4RHCbBg6vA4fXidPrRjxexOlBOVxElRBVEInFCEUV4ViMUCRGOKqIRGNEowoVU8RiCqUUKFBKoWIxUDG7L/6qAHu/OEqhkpbthV3/3Qdxpr7yNzYopQr39Hgjq0wRCaR6rpVA8s6z7HEuVUqBbUnrlXZfb/17zUAP+icopbaLSBHwpoisSd6olFL2F8JO2H+4WQBHTzpcvf/BBzja63hkoyL/gnPpfPw12kMRPj/xND769kNMH1+E57IL+fVzfyXjmqf46R9/TM755/JWXSf33fcjTlxUwcr/zOanf/wx575xN3ff+R+mZHu48pG7+IcxlV/cO4eWrasxnS4mnH4Wv79qCjNi61n/29/y3+dX82lLgKhSjE5zMeWwfCq+MJHccSPwHH8+jTkVfFLdwYLPG/nvunrqt7XRWluHr3E7wY5mIv4OVCwKgBgmhsOFw+3F4UnHmZ6N05OBMz0bT7oHt9eJYQpurxO314HH6yQnzUmGx0mG20Gmx0GG3Tymgdth4jQFpyG4HSYeh4HTELvPwGlaXxKmiP2lYH1ZmAb2F4XYfdYXRnwf2NEH1hcK7BiDjaTBWJK+LYwUvxyM7t8wvbCr3X6YNo6/HnYaX17yDk9Nv4p/533C2H++yNALfsPCe0/inUt+zFcnXM19d13OGxOP5d5//4mCWxZw4qVf4Hcf38ND/1jKl8aXkP7CHM647g94sgt5/P5ryP/T9/jzfe+Rbhpce+2JZP/0Ib71/AqWLatl4wdvEIuEKJl8KqecNoYfnVrBuMgWWl7+J2ufXciKZXWs6wjhj8aIKsh2GAz1OKnIdlN4eAGFE0spmDQa95gjMMvGEskZRmvMSWc4Rm1nmO1tAao7gmxt8FHd6qeuLUhne4iAL0TQHyEcjBCNxAgHQ0SDfqIhP7FIiGgkRCwcIhYJoWJR64HD/szFYlFU1FqO98Vfuy/vqm+wEF7yjy179QbRIM7xX0xp19CnfwskSdeDggGVd5RS2+3XOuBFLG2q1v75gv1aN5DXoNFoNLuLGGZKrR/YDgxLWi+z+3rr32sGbNAXkXQRyYwvA2cCK4DZQHwm+hrg5YG6Bo1Go9l9ZF8O+rOBq+0onmOBVlv+ngucKSK59gTumXbfXjOQ8k4x8KL9098B/Fsp9R8RWQQ8IyLXA1uASwfwGjQajWb3EOmvAR0ReRI4BSgQkUqsiBwngFLqYWAOcC6wAfABX7O3NYnI/wMW2W/1S6XUriaEU2bABn2l1EZgcg/9jcDM3XmvVXUh5o87hv+97vfMG/8ZP6rv5Plfv0DlTw/j09NHMmvOq8y7+S5+HFUs9ExAxaJcNbGA2xp9lHgcGKdcReU/HiW7bCxnVuSz+UcrCcUUoypyYcwxvDunGl/jdiKBDtIKxlJWlsXwbDehT1bSsqmZ+mCUUEzhNYU8l0lagZf0knzM/CHE0nLpCMdo9odp7LR011AwktBaY+HQTvpo8pOCYWv8psOayBUDTIeB6TAwTMPS43tqYk/yxvV36brcpdnKelwfT0VOT/UnoKSozQ8EV50yghVfuJpLoyt4Cpj13GpWHreQQGsD8y67lZP/9hOabvoP57pn8LbAuuJj8TU+xY9PH8vSn65jYpab8ZdO5defVOJrrGLE1OM5PN/JJx9spDUcY2KWm4Kph/N5W4hNlW20NTQTCXTgzswjIyedMcUZ5HlN1KbtdG5vwNfgpyMSIxRTRJU9iWsIGQ7BleHEneXGlZmGmZ6B4UlHOTwoh5uQ3/p8BSMxgpEY/lCUYMSazI1EYkSjMVRM7WhKoWLRRIslLQPWBG+KDGbtfqAQEUynq1/eSyl1RR/bFfDtXrY9AjzSLxeSxEBP5Go0Gs2go7+e9A9E9KCv0Wg0yfSjvHMgogd9jUajSUIAMQ5eW7JBcWfB9hbeqGzjsxef5L5r/srXv3gYLVtX8+YXf8KUR/6MikZpuOdmzhmWxU+eXUbR4TOIvnwf/qhiRnk2b24L0LJ1NaUTDqO0cxPrVtTjNYWy48upMXJY93kTgdYGANILhzNlRC4lHkVg8+e0VbbRFrF0zwyHQZ7LJKMoHXdRAY78EkvTD8VoCoRp7AgS8oeJhKNEQv4usdJxxDCthCzDxHC6ktYF0zQwTcPS9m3N3uWwdH2XaeB27ND4LQ3f2ic5cat7nHwcIxF7nxxTv3OM/q7oL/W+P2L0AVyPvcw7XzA5duEC7vp/1zMt18vCp55h+qWX8OLqehYUnUrB2GmsvOPnnDUih9tfXUV64TCOTWthUXOAKceVUvilr/Duom2IYXLUpBIc6z9g4xrrszCsPAfPEcexpLqdpup2Ouu2WufNyCW7II3RBenkuiBSu5XOmkZ8TZamH7UTm0wRPIaB1zQsPT/diSsrDSM9CyM9k5jTS1hBKKaIRCEQiRGIWpq+P2zp+nE9v/trVw1/5zj8OLEe4vH70vG1zr9Po3f2OfpJX6PRaJLR8o5Go9EcQohg9FP0zoGIHvQ1Go0mCUvTP3if9AeFpj9s+BB+/sfLmPLlKwkrxbBHX+SYyy/n5S2t/O/SGJO+cAGvPPAeJ/3mEla+/R5nnD2RT+6fw/hMN5OvP4E/zttALBJi5vRh+Be8yLqOEOVpLoaceiyfVLXTsL2FWCSE6fKSW5LDEUOyMJu30rxuG02Nlk4LkG4apOV5SRuSh5k/BCO3GL8yafaHaeoI0dIRIhSMEvF3EAtbfig9afpWbL4z4cNjOFw7tPy4tu+wlw3B5TATWn5c4zdlRzx+fBksHdk0drxKFy+dHT46vRqm9bChu9bf17xB4r16/RftH2Z+7ffcO/V6pt3xJtfXvsSVs39BWv5QXv3WMYzNcHPzXxZyyeUnMPvl9cy480I+fvMzRh1zHC1P/omOSIzxXz2VqryJVK1eQ1r+UC6cNISWd+fyeWeYPJfJkClDCA85nMVbmmmvqybU0YwYJt7cEgoL0ijP8WK21RCqrqS9uoOmUJSAHaMPVoy+1xQyHAZOW893ZaVjpGehXOng9BCIKEJRRSASw2fr+P5QlJD9Gk3o+iT0/FhMoaJdY/Ohdy0+rvdrUkS0pq/RaDSHEIIxSAf0VNCDvkaj0SQjB7e8owd9jUajSUIQDIeeyNVoNJpDg4M8ZHNQTORmNW/nobHX8d7XR3PLX67itF/NZ+63pnFWcTqzZr3Oo1+fztLWAJ3nfp+O2s389PQK5i+rY8YJZeRdfiNrFm8hvXAYV04p5fOX/0tTKMq4knRcR53K/PUNtFdtQAwTT3YB+SWZjM1PI7ZtDS0baqkJRPFHFS7DMltLL04jvSQPR0EJ0bRc2kIxGnwh6tqCO4pchKziFt0n0OIfpJ4mhAyHNXmbPKHrchg4ejFci5utxSdxTQEzXnUryWwtce49MFvry0xtf5qtAWQUjwRg/bwXeeArD/FAZAo/uOUSqm7+Clf8/GzWz3uZe84axTZ/GC7+CY0bPuVb549n6d/eZ5jXiev0q3lpbT1tlesoGHMkJwzPZts7y6kPRhjmdVJyzAS2B02Wbm7C31xDqLMVhzeDjIICxg/JYkiGC7OthvattXTWdtIajuGP7jA7syZyDdyZLjxZblyZ6Tgz0jHSMlEuLzGnl1DUmsj1haMEo7FEUlYoEiUSiRGLKmKRGNHIjkncWFKAQE9ma8lGbLtCJ2H1hp7I1Wg0mkMHATEH54CeCnrQ12g0miSEg1ve0YO+RqPRJKM1/f1PTW0Hd93+AK9OPo+XJt7A6rnPsfKyi/jCsz+jZfMKhi94mGm5Hm55ZTXZw8dTuvo1qgIRDv/mhayQUhrWLaLk8KOZ4PWxccFWXIYwfEYZLTmjWby2Hn9zLQ5vBumFwzl6ZB5lmU5CG1fSsqWV5nA3s7XidNJK8iGzIGG21uAL09QZJBgIEw5GupitJeum3fVA0+HCcLqsgilimawlG68lJ2N10faTzNYgWcvf2czMoGcjtb7M1rrr9X2p932ZtSWft79YOetKfvDxLE79+vV0RmP8+lePc+uQKh55dAmB636FN7eYhntu5tg8L7+etwmHN4OrJhbw/sZmjj8sjyX+TJ58dxOxSIhRhxeR17iGbQuriCoYVZRG+pHHsaKuk4bt7QTbm1GxKK60LDLzvIwpziDfaxKu/JyO7fVdCqiAped74gVU0q0CKu6cDCQ9C0nPQjncRDAIRWMJPT+emOUPR/GFokSjlpYfs4unxGJdi6d01+R3pdFrs7Xdw3Q4UmqDkcF51RqNRjNAxB++DlYGxZO+RqPR7Esk/su7j5bie50tImtFZIOI3NrD9vtEZInd1olIS9K2aNK22f1xb/pJX6PRaLph9NOTvoiYwIPAGUAlsEhEZiulVsX3UUp9P2n/7wBHJb2FXyl1ZL9cjM2geNIvzvdSevRM5tX7uPmnjzF25pd45LX1PJ1+AqNPuYg5Nz3GuT+ayZsvfsDkM45j2W/+yjCvE868kT/M20C4s5VjppURff85lrYGGepxMOz0qXxW00nt1harIHr+UHKGFDNleA6e1kqaV2+hpbqji9ladp6H9JIcHIWlRNPzCTm8NPrCNHQEaewIEfJHCAd8RIP+HjVXwC6YYuwooGKYmKZhx+lbTQwScfqmYWBKktGaITsXPpcdRVW6m611ObcMnNnaTu+V2m69H5/CG7xbMY2Zc4XXT4cfPngFkUAn/znru7gM4bKHF3L8xefyygPvceb3T+Gpl1cxfNqpRF++j5pAhCO+dgJ//WgLmz5bize3hCuPGY7vvdksbw2S4TAonTaE2Mij+HhLM621DUQCHQCW2VpxBqNz03B31hOu3kxHdTutgQid0ViiILop4DUNMhx2AZUsr2W2lpED7nSUK41gVCUKovvCUXzhqKXp24ZrcbO1WFQRU0kF0ZMKpsTXtdlaPyIkcmX6aikwHdiglNqolAoBTwEX7mL/K4An++EuemVQDPoajUazr7Cslftt0C8FtiWtV9p9O59XZAQwEngnqdsjIotF5CMRuWjP7qgrWt7RaDSaZMSKoEuRAhFZnLQ+Syk1aw/PfDnwnFIq+efZCKXUdhEZBbwjIsuVUp/v4fsDetDXaDSandiN6J0GpdTUXWzfDgxLWi+z+3ricuDbyR1Kqe3260YRmY+l9+/VoK/lHY1Go0lCxJrITaWlwCJgjIiMFBEX1sC+UxSOiIwDcoH/JvXliojbXi4AZgCruh+7uwyKQd9fPILl957LT35+JmFfG2/97FQmZ3u47Q9zmfWdGbxV10n2zX+gaeNSHvjyJN56dyunTCnhyRV1fPj+Fry5JVx/7Ag2v/iWNYmX5yXtuHN5e109LdvWAZA1ZBQFpZkcUZSJqlxN07oqtvsj+KOxHWZrRelklBZiFpYSS8ulNRBNmK35OkME/WGralYkRDQc6jExy7QrZSVXzZK4gZppYJiC6TASZmsue7l71SzT/rwl1nsxW+teNasvBsUHwuajJj8f/vMx/nbM9bw+9VtccdNVvFLZxnU3Hc+Sl1/g8a8cydLWAPnf+w3Vn73FdRdN4JP751DicZDz5Rt4779bad68gryKKZw+Ko/Nr39MrW22NuS4CdSQxX/XN9BZvxUAhyeD9IISxg3JYli2G7O1ivattYmqWXGzNVMkMYnrTXfZiVmZODPTMNItszXVzWzNF96RlBWKWBO5sahKMlmLm65Fuxiq7anZWk/oxKwdWMEUfbe+UEpFgJuAucBq4Bml1EoR+aWIXJC06+XAU0opldQ3HlgsIkuBecDdyVE/e4qWdzQajaYb/ekgq5SaA8zp1vfzbuv/28NxHwJH9NuF2OhBX6PRaJIQsX5tH6zoQV+j0Wi6oW0Y9jObt9Qwf9wxfHLJL/jhHddR/81LuPrJH1C36gOmrnqKydkebn5lDVllYxm79R02+8Ic9f0LmfWfddSseJ+Sw6dzTF6U9f/ZiCkw8tQRtBVN4L0VtfgaqnCmZ5M3JJMpo/IZnu0ktGEZTeubaAhFiSrwmkKh2yRzaAbppYVITjHtEaEtFKPRF6K+PUDAt8NsLRoKdNFaeyq+kGy2Ftfyk7X9XZmtxSeR4gVUoHezNUjS9ROve2+2lrzP/jBbA/jf+b/luKuuZrMvzE0/fZyHp0a4cEQ23p89jCs9m9CffsSUHA/3fFSL4XDx7ellzF9Wx0lj8lglQ6lZ+QnRkJ/Rk0ooaV3Plne3EYopDitMI+uYE1lW20ldZRuB1gYMhwt3Zi45RelMLM2iKM1hma0lFVCJm615zR1ma+4sF95cD66sNIzMXIz0LJTTS1gcBCIxAmHbcK2b2VokHLWSsyIxYgnTta6JWcn0pMd33zd5H63f7wKh1wTI7m0wop/0NRqNJol4ctbBih70NRqNpgsHt8umHvQ1Go0mGek/w7UDkUGh6TvTMnmjso1rfzCLn8iHPPz0Kp4uPIcxp36R165/iC/dfgazn36Xo885kaW/+KNltnbuTWxYuJhwZysnzBhBdMFTfNoSYJjXyYhzjmFxdSfVm5oSZmtjRuYyvTwXb2sljcs+p7Fqh9lalsPcyWytNRil0Remtj1IXVuw38zWDLswetxszWUaO5mtOQ0jyWSNXZqtxT+7icLovfyNB5vZGsAZH+bzzjlw68NfIdjawJwTvsaZcx7goj/+l5MuP5/n736L8388k0eeXsLI484g9sJvqQpEmHzjyTywYCOd9dvw5pbw1eNG0DnvBZa2BMhwGJQdOxRVMZ0PNjbSvL2GSKADV3p2wmxtTF66Zba2/XPaKltp8oe7mK3FC6JnO82E2Zo7J9MyW/NmdTFbi+v5KZutdW+7MFvT7BkCGKak1AYj+klfo9FoktFP+nuHiJgi8pmIvGqvjxSRhXZBgaft1GSNRqM5YOhHl80Djn0h73wPK/04zj3AfUqpCqAZuH4fXINGo9GkSGpVs/oza3dfMqCDvoiUAV8A/mavC3Aa8Jy9y2PARQN5DRqNRrM79LPh2gHHQD/p3w/8GIjZ6/lAi21CBLsuKHCjXTxgcbE7wJ0PXYGKRXn4S3dzUkEaP/n1Czz1o5N4q64Tx7fuoWnjUh68ZBJz5m3h9BllPLKkmrbKdaQXDuN/Zoxkw5P/oSYQ4ciSDDzHn8+cVbW0bF2DGCbZpaM5fkwBR5ZkEtu8bCeztUK3ZbaWObwYR8lwYun5tAai1HUGqW4JEOgM75XZmuno3WwtPoHb3WwtbrJmiOzSbM1KwrLX+/jHSv4w7OrzfKA84fz3X//k3uk38s9xX+N7t13Pq9Xt3F09lCUvP8czVx/FirYg2Tf/gerP3uKmS4/g43teZZjXSdYl/8P7H2zBdHkpHDeVcyry2PjqQqoCYcrTnJSdPJnt0XQ+SjJb8+QWk1k0hIml2ZRluTCbt9G2qdo2W4slzNZchpBum6250px4cz24czJxZWd2MVsLRBTBSM9ma8FQ1JrATUrO6k+ztR4TufRkcBe0vLMHiMh5QJ1S6pM9OV4pNUspNVUpNbUgP7+fr06j0Wh6RoSEu21fbTAykNE7M4ALRORcwANkAQ8AOSLisJ/2d1VQQKPRaPY5wo5fzwcjA/ZVpZS6TSlVppQqx/KKfkcp9RUsX+iL7d2uAV4eqGvQaDSa3caWTlNpg5H98fvkJ8APRGQDlsb/974OaFixlgdHX8tffv8NqgJhLp7/EC1bV1P20m84tTCNrz6xhPyKKZQt+hdVgQhH3vY1/vbKahyeDMqOnM4kVzOr3t6MyxBGnzma+pwKPlxeg6+xCld6NoVl2Uwdms2IbBeBNUtpWNNEQyhCVEGGw6DQbZJVlkn60CLILqIlFKOuM0iDL2ybrdkFVGyztVgktFtmayKC4TAsE7VuhVO6m605TWu/RHKWIb2arSV/JvvTbK3LefrZbG13pguuv+N7ANz2kwf5mfdTvnJsKff+4VkySsrZ/sOrOb0onZtfWYM7M4/rx6Xx1tpGTplSwocdmVQv/y+55ROZPLWUgtolbHi/kqiCcWVZZB4/k0VV7dRsaSHQ2oDp8pJeOJzc4gyOKM2mJMNJeOs62jZX01HVQWs4mjBbcxlChsMg22ngyfXgyfXgzsnAyMzByMxFudIJiYNQNJbQ8zvjiVm2rh+N2lp+bEcRleRErO7Jf7trtqbZNcLBPejvk+QspdR8YL69vBGYvi/Oq9FoNLuLCDgG6YCeCjojV6PRaJIQkUE7SZsKetDXaDSaJCx55+Ad9A/eO9NoNJo9pD81fRE5W0TW2tYzt/aw/VoRqReRJXa7IWnbNSKy3m7X9Me9DYpBP6rgrtsf4MTXfsUtvz6fm1blMu3Sy/jHj1/ggllf58Pn5nDplSfz4a3/YHK2h/ojv8Tmjz+k6PAZfGnmaHyv/p1PWwKMzXAx7PyZLNjSSvXGOqIhPxnF5RxRkc/oXA+u2rU0LNtAXV1nwmEz12mSXZRO1vAizOLhRDOLaQ1GqesMUdXip6EtSNAfIeLvIOLvIBoJ7TRpJoaJ6XRhOJwYTlciMSvZYdMwBCPJUdPlMBMOm/E+Z7cJXMthkx4dNhMum0ifk6OpTJ7uK4fN3eHu1mf5wcezSC8cxsMX/JJjXn8RX2MV377pIv71908590/XMPvpdxl/2uk0/vkXNIWiHPX9C7nnzXUEWusZNWUcNxxfTsPsZ1jaGiDPZTLipBFERk5n3rp6Wqu2Ew35caVnk1OYTunQTMYVpONs3kZgy+e0VbbREIx0cdj02olZWU7TTszKwJ2biZGZC55MYu4MKzErGk/MsipmdQQiCZfNZIdN6zW2k7smsJPDZirVtDR9I/0YvSMiJvAgcA4wAbhCRCb0sOvTSqkj7RZ3MMgD7gSOwZoHvVNEcvf2/gbFoK/RaDT7inicfj896U8HNiilNiqlQsBTwIUpXspZwJtKqSalVDPwJnD2Ht1UEnrQ12g0mm6Y8RoVfTSgIG4XY7cbu71VKbAtab0365kvi8gyEXlORIbt5rG7hZ7I1Wg0miTiNgwp0qCUmrqXp3wFeFIpFRSRb2AZUZ62l+/ZK4PiSb/k8FGUHj2T3/5sDp+cdzv/vP9R3vz2dDb7wiw96hr8zbXcc9Yo5qxu4IyrJvGrdz7H11jFMSeM5PppZaz85wJawzEmjcvHmH4+Ly3ZTuvWVRgOFzllwzmxooAcfy2R9Z9Sv6LaNltTeE3LbC1jaAaZw4txDi0n6Mqk0Remui1AdWsAX0eIQGeISMAyW4v1ZLZmmjuZrpkOh63n72y25k4yWksYrtlJWXGztR2Vs6SL0ZohssNgLenXp7DrBKk9MVvb36HMt3/9X8ycK7xy39VUBcKc9egajrn8Uu4cYyVMbT7xmzRtXMrvr5rCgvvmMSXHA+fexLL3VuPJLuSrp4zi1OEZrH/pU+qDUcZnuig9/VjWtcVYsq6BjtrNAKTlD6WoNIspI3Ipy3JBzee0bthO27Z2mkJR/NEdiVnpppWY5c522YlZmThzcjAyclDudJTTSzASIxCJ0RGykrM6AhF8oSj+UIRIJEYknGyylpSc1YfZGmBti/au5Wuztb6Jx+mn0lJgOzAsaX0n6xmlVKNSKmiv/g04OtVj94RBMehrNBrNvqKfNf1FwBi7eJQLy5JmdpfziQxJWr2AHfVH5gJnikiuPYF7pt23V2h5R6PRaLrRXxYLSqmIiNyENVibwCNKqZUi8ktgsVJqNvBdEbkAiABNwLX2sU0i8v+wvjgAfqmUatrba9KDvkaj0SQRD9nsL5RSc4A53fp+nrR8G3BbL8c+AjzSbxfDIJF3VtWHWX7vuRyb5+Wa257Am1vMyssu4iunlXP9Ax8w5tQLabjnZqJKMfInP2POnJWkFw7jxzPHMnTbhyz6rJY8l8mYi45iQySL5Svq8DfX4s0tZujIXKaVZqE2fkrrkiU0rbfM1gCynSaFaU6yh+fgGTaMaFYJzYEo1e1BKpv8VLf4CXSGCPn9hAMdREOBXRRPSYrRd7owTMtsLTlWf0fxFCtG350Uo5/Q7xPLOz6YyTH6ceKfWZGu2nt3s7Uuun8vZmt7+/kfCLM1gCuPH8aH/3yMnN98nR/c9QX++8S/+c83pzP/ov/hitNH8rVZC8mvmMLxviUsaPBx8iUTeGRJNQ3rFlE04Ri+OK4A+fAZlq2ox2UIFZOKcE8/i3c3N1G3tYVgexMOTwZZJWVMGZHLEUOyyDOChLespnVzLS0NPtoisYTZWjxGPy3LjSfHgyfHiyc/CyMzFyMrj5g7nUBUEYgq2oO22VrI1vNts7VIOGrp+dEdTcWiibmihJ4fTd1ITWv2u4c2XNNoNJpDCO29o9FoNIcYg/UpPhX0oK/RaDRJ9Lemf6ChB32NRqNJIq7pH6wMCuEq0NbC/HHH8OUlL9JRs5k//O9XeOS19Uz592NseHc293/jGF554D3OHZPH6x1F1C5fwKhjjuNItrHlkUdY1xFkWq6HogsvYfbqWmrXr0XFomSVHcZphxdTnmniW/4JdZ9tYFtrkI5IDJchFLisillZI4fgHFJOLLOIlkCU6o4g1a1+2tqDBHxhy2gt6CfaQ2KW4XQlJnTjRmtWcpZttObYMaGbbK7WfblLQlbCeG3nSdLuZmtx4hWzeqKnD8GefOT39X+TnGdf47irrub+vyxm+Rd/Tt6oyay/7ss8s7yOKY/8meWvv8KlV57MZz/+NRkOgzE//jF/e2U1KhblhBPKydv8AZufeYV1HUGGeZ2MOnsSjVmjmLu8hpata1CxKN7cYgpKs5hcls1hBWk4GjfTvmEzLZtbqQ9GE8Z8yYlZ3lyP1fKzcedmYmbnE3Ono1zWRG4wohJVszoCETqCEToCYdtsTdmVsxSxeHKWbeK3k+Fa0mt8kjdOqpO3epK3Bw7ycon6SV+j0WiSEATnQeynrwd9jUajSUKwrE4OVvSgr9FoNMkIGINUukmFQfEbpmxYCW9UtnHyP7dz3Q9v4JKNTzI528N1c+vIKhvLSXXzWNoa4IR7ruEXzyxFDJNvnT+e2sceYtnTyzFFGHfOaFqGTeeVhdvoqNmMMz2bkvJCTijPw1W1nNrFa6hf1UBVIEJUQYbDoMTjIKc8m6zyIUhBGa0Rg+r2INub/DTaZmshf7hLYlZcI03o+IZpJWY5XFaSltPW8+Mma6ZluuZwxJOxzESS1g4930rKcpqS0PatIipWQlZ3s7XkpCtDumrtyYlZycQTs/bUbK23w1JNzNoTTvza/bxzDlxQkcdVt/6bB392EY88u5pj87z879IYYprcc9YoXp23hbMPL+QT12Fs/vhDcssn8p0TR1H11JOsfWUd/qhi0tAM8meezUfb29m0rhF/cy2Gw0VGyUjGDM/h8KIMSjOcRDatoHndNtoq42ZrlqbvNYUMh0G2x4En10NaQRqe/CzM7HyM7HyUK52w4cIfjllafiiS0PT9doJWJGy1aMQyXIvFFNFIJFEspXvBFKvFuvxNuput7arIiqZnrCf9lK2VBx36SV+j0Wi6MZAPK/sbPehrNBpNElrT12g0mkMIEcFhDgrle48YFHeW01rNnQ9dwaKn/8X95dv4v2v/ytVP/oDZj7zA1244l3dvuIcpOR7qZlzHunfnUzL5VK6aWMCyf3zEB41+xme6GXnZeby5sZlta7YTCXSQNWQ0UyYUMbEojcDS96ldWkO1rdOaYhVEzytOJ7u8GGdZBdHsITQHo2xvD1DZ7MPfHsLfHiLU2Z4oiB6LhLpcd5fY/F4KopsOI1EQPdF6KIjuNAwMEZxmPGa/ayGVvgqix43WulxfPxZE31v25Ne0J7uQe6ffyCmfzqOt6nPOWPpXhnqcXPaPb/GXh19l0rnn0XDPzdQEIhz7i69w2+yV+BqrGHPsJCY76ln1zBIWNfspdJuMPrOCyPhTeHVFDY1bNhMJdODJLqCgNI9jRuUxLNOJp2Ur/g1raNnUTL0vTFsk2qUgejxGPy3fiyc/E09+NmZ2vlUQ3ZOF3y6I3hqM0BHaUTzFl2JB9GSztVQKomsNf8+JFyvqqw1G9JO+RqPRJNFXlbnBjh70NRqNJhntvaPRaDSHDvpJX6PRaA4xBqtenwqDYiK3uqadB0dfy6QLLuOR02+hLRLj2aJziYT8/Gqah5fWNnL+j2dy0/PL8TfXcME5hxF9+T4WVLbREYkxZdoQZMal/PO/W2jZvALT5aVo9CjOHFdEdusm6j5eTvWmFjZ1hgnFFF7ToMRjkjsqh+yKUhxDR+FzZFDTHqKy2U91i5WYFfCFCPtaiYYCicpGccQwMZ0uxDDshKy40ZoDw2HgcBo4nCYO546qWaZh7FQxy2UaGIYkJo66T96a3RKzYOfErOSnlu7VsZI/AIlqWz38G+xJYtZAs/xv1wAw/a4PuOr71/GnGx/n6/dezPyxl9G6dTX/vGE6rzzwHqcXpdNy0vWsmPcJ6YXDuPnsw2h/6e98XNVOfTDKlBwPZeedzpL6IJ+urKWjdjNimGQUj2TYiByOGpJFemctattqmtdto2WLZbbmj+6omJXlMMhzmXgLvHgLrElcZ24uZm4hMU8mMVca/kiMzlCM9mCki9maPxQlFIoSCceIxCd07eSsWDjU1XAtmmy4Fkssx5KqafVET5O6eqK3Z8QOmEilpfh+Z4vIWhHZICK39rD9ByKySkSWicjbIjIiaVtURJbYbXb3Y/cE/aSv0Wg0SVgPSv30XiIm8CBwBlAJLBKR2UqpVUm7fQZMVUr5RORbwG+By+xtfqXUkf1zNRaD4klfo9Fo9iX9aMMwHdiglNqolAoBTwEXJu+glJqnlPLZqx8BZf16M93Qg75Go9EkEZdEU2lAgYgsTmo3dnu7UmBb0nql3dcb1wOvJ6177Pf9SEQu6ofbGxyDflGuh7tuf4APv3cEq9uDfOd/z+ZHv3qeE668mKXX3chQj5Psm//Af195l4Kx07jttFF8cv8cmkJRytOcTLxuJu/VhFm3rIZAaz0ZJeWMG1fAtKGZRFZ8QPWizWzqDNMctjTOXKdJSWEa2SML8IwYTSR7KA3+KNvbAmxp9NHZFiTQGSLk6yTs70hornHiSVnxVzMpQcvS8c0uiVlel5nQ8d3diqcYYiVmOUzD1vJJKqISL6rSVceHnZOdumv3XRO3en5i2dufuKlGQOxpoMRHE47lBx/PYvXc53josDqaw1HWn/0jvvX7+Yw+5SKGvv0AS1sDnHLH2fz0P+to2riUUcccx3kjPCx/dAFVgYhVXGVmOcb083h5RQ01GyoJtjfhzswjt7SEGWMKGJXjRipXEdywjKa1NTQ2B2gORwnFlJ2YJWQ7DdLyvKQVpOEtzCWtKBcjpwjSc1GeTHzhGP5IjI5QBH84SkcwQrtttuYPRBJma/HELKW6Fk+JxboWUelNj9c6fT8gWPNlKTSgQSk1NanN2uPTilwFTAV+l9Q9Qik1FbgSuF9ERu/NrcEADvoi4hGRj0VkqYisFJFf2P0jRWShPanxtIi4BuoaNBqNZneJF1FJpaXAdmBY0nqZ3df1nCKnA3cAFyilgvF+pdR2+3UjMB84as/vzGIgn/SDwGlKqcnAkcDZInIscA9wn1KqAmjG+jmj0Wg0BwS7Ke/0xSJgjP2w6wIuB7pE4YjIUcBfsAb8uqT+XBFx28sFwAwgeQJ4jxiwQV9ZdNirTrsp4DTgObv/MeCigboGjUaj2W12T97ZJUqpCHATMBdYDTyjlFopIr8UkQvs3X4HZADPdgvNHA8sFpGlwDzg7m5RP3vEgIZs2uFKnwAVWGFLnwMt9h8CdjGpYU+I3AhQOKSM0qNn8ubks/n+j05h0xW/pOWFO5h9zXXc+t2NfPub07jltbW0Va7j4u9/i5z/PsH8ZXUM8zo5fmIhzjOu5ZE5m2lY9ymGw0XR6HFcOHkoxaFaav+7iJpVDTSErCLXXlMo9TrIHZlD7tjhOIePpTMtn7o6H1tb/FQ2+fC1BQl2dhDubCUa8hMJ+ruYrYlhIqZVPMV0ey1d3+XF4XLbRmuyo4hKwmjNxGUaiYLLceO1eOEUU8BpxjX+HTH6iSIqtsGaZaxmx+vTtSD67sToG71o/gdKjD7AgtoOfjdXmHHNtfzrtG/w7VtO5rS751H1yVzefv53vHrsrUzJ8ZD29V8x94Yn8GQXcuN544m89hAfrqgnw2EwOdvNqC+dytpgOvOXrqZt+zoAMorLGVqew9Gl2eSEmwmu+4ymFZto3thCTSDSpSB6lsMkz2WSVuAlvSgTb342rvw8zOx8lCeTmDsTvz+KPxyjNRihPRSl1RdO6PqWnm8VTokXUIlGYjtp+D3F6Cf0/t0snqK1/97p74xcpdQcYE63vp8nLZ/ey3EfAkf024XYDOhErlIqaseYlmGFLo3bjWNnxSdHsvPyBuoSNRqNZifiD1B9tcHIPknOUkq1iMg84DggR0Qc9tN+j5MaGo1Gsz8x9utv2IFlIKN3CkUkx172YmWkrcbSpi62d7sGeHmgrkGj0Wh2F6H/NP0DkYF80h8CPGbr+gbWBMarIrIKeEpE7sJKP/77AF6DRqPR7B6DWLpJhYGM3lmmlDpKKTVJKTVRKfVLu3+jUmq6UqpCKXVJckxqb2zcXMPye89lzvY2ar91L5fe8RLTLr2MdTdcRrbTZNhvZvHik/PJKZ/Ib74wnk9/8y+qAhFOPKKQyTeexsI2L58s2o6vsYqMknLGTChkxvAcYisWULXwczZ0hBMTcwUuB0PyveSOKcQ7egzR3GE0+CJsbQ2wsb6TtpYAvvYg4c5WwoEOoqFAj4lZOwzWrElcw+nCMI1EcpbDZb0mJ2R1b3FjNcOQXhOzkidqkxOzekusSjUxa28Z6MQsgF++8f/48J+P8dZFWSxtDeC7+QG2/vdVhh93HlNXPcW8eh/n3XIqP31jA3WrPmDksSdzzREFLHlwLpt9YSZnuzni5OE4T7yYF1fUsH1dFYHWetyZeeQNG8ZJhxUyviANY/sqGpd9TuPq7dTVdXZJzMpwWBWzMnI9pBV48Rbm4i4qwMwtwsguIObNxhdRdEZitNoGa22BMO2BCB2BMMHQjkncSNiqnBWNxohFQgmztVi3hCw9CTuwCFZgRCptMJLSoC8iXxKR9SLSKiJtItIuIm0DfXEajUazP9ATuZbr2/lKqdUDeTEajUZzIHAQF85KedCv1QO+RqM5FBBI1UFzUJLqoL9YRJ4GXsKyVwBAKfXCQFxUdxzeDOaPO4Yf/ehkTrjtBerXfMSGv17OT7PX8I0bpnDz3C00bVzKF7/3TYo/eZrHPq5imNfJkd88He95N/Dn1zdSu3oxhsNFYcUEvjyljKGRemrf+5CapXXUBq1csURi1qgc8saV4yofR2d6IdV1PjY3+djS0JlIzArtRmKW4XThcLlxuMydErO8LjORmNVF27cTs5yG3XpJzIonY+0qMcvA0u6Tn14Ge2IWwNlLhnHcVVfz+NFX8L1bTuKMX77N8OPO4++3nMTs405iSo6HnFvu49kbn8Kdmcf/fPFwYq/8H+99VoPXFCadVs6Yy2ayJprL64sW07J5BWAlZpWU53DciFzyI80EV31M4+rtNK5vpiYQoTXcNTGr0G2SXpROxpBs0opyMXOLMHOLiHmzibkz8e0iMSsUjNh6fjSlxCyr9ZyY1ZPmrxOz9oyDeMxPedDPAnzAmUl9Ctgng75Go9HsSwZpNGZKpDToK6W+NtAXotFoNAcC1q/mg/dRP9XonTIReVFE6uz2vIgMaHUXjUaj2V8YklobjKT6K+YfWHagQ+32it23T5hYlskblW1suOH3NKxbxAnXXM3Kyy4iy2Ew7N7Hee7xN8ivmMK9Fx7OojsfoSoQ4ZQpJXgu+h/ea/Xy8Ufb8DVWkTl0NJMml3BqeQ7Rz95k23vrWNseoiMSI8NhJGL0C8aXkDbmMCJ5I6j3Rdjc7N8pRj8a8qcco+9wuXfE5/dzjH5cw08lRj++fcfy4I3RB/jgsUd55xxY0Rak5bsPsOXDV3jy1lOZtvivzKv38cWfn8Mtr62ldsUCKk6cybUTsll87yts9oWZlutl7JVn4jj1Sp5eUkXl6m0EWuvxZBdSMHIkpx9ezITCNIxtK6hfsp6GtY3U1XXSEOoao5/nsmL004vTd8To55cgOZam35lCjH7ccC21GP1Yyn8frd3vOQdzyGaqg36hUuofSqmI3R4FCgfwujQajWa/EI/e6acauQccqQ76jSJylYiYdrsKaBzIC9NoNJr9QorSzsEu71wHXArUANVYhml6clej0RyUSIptMJJq9M4W4II+d9RoNJpBjpXjsr+vYuDY5aAvIj9WSv1WRP6IFZffBaXUdwfsypJoWr6WOx/6PhU/+DsXfvs6/nVOITffvJ7b7zyLy59YSuvW1dz405vJfetB3vishtHpLo763vm8USM89O566lYtxHR5KTlsApceXUaJfxuV8z5g+8oGqgJhAApcJqVeBwWH5ZM/cRTOkYfT5sljW62PDQ2dbKzroKMlQKCtlVBnK+FAZ2KyLfH3MkxMpyuRmGW6vJhuLw6nieEwcDjjhmtGl8Qsr9MkzWXuUWKW9e+0IzHLkN4TsxLGbEl/28GamAVw5Y9u4t7pl3PbfV/myFtfYvxZFzPmP7/jXz95gVML04hedxcvXvc30vKHcttlk/H9627mL6sj22lw1HkVmKd+laWtJnM/XkHLlhWIYZI5ZDTlFXmcNDKP/EAd/uUf0bC8kpp6HzWBaMKYz2sa5DpNCt0OMoZkkDEkm4yyQsz8IUiWZbQW9WTR6YvQEbQSs1qDEVp9YVr94URiVmISNxIjErITtOzPVU+JWUDKiVk9oSd3U+NQDtmMWy8sxip72L1pNBrNQUX8Sb+/NH0ROVtE1orIBhG5tYftbhF52t6+UETKk7bdZvevFZGz+uP+dvmkr5R6xV70KaWe7Xahl/THBWg0Gs2BRf9F5tj1RB7EKiJVCSwSkdndCpxfDzQrpSpE5HLgHuAyEZkAXA4cjhUq/5aIjFVK7dXPtVQncm9LsU+j0WgGNynG6Kf4vTAd2GDXEQkBTwEXdtvnQuAxe/k5YKZY+tKFwFNKqaBSahOwwX6/vWKXg76InGPr+aUi8n9J7VEgsrcnT5VQTPHg6GsJd7bx5Ikw/5SLmZztIXLTH5j379mUTjuX3587hgW3Pkl9MMrpp5cj53+XP8xdy4qPPifQWk/O8PGcML2MU8pzCH30Glvnr2dVWxB/VJHtNBiZ7qR0aCaFE8vwjp1IJL+cWl+Ez5t9rK9tp73Jj78jSNjXSqQXPd+IJ2W5vDhcltmaw+VMJGWZDkvLN0xLz09zmXhdZiJBy+uyjNcsLd/AYRo4TQNTwGn2nJgVT8aKL+/4t9uh5/dEX5rlnmqa+yoxC+BP6lUAXj72O9Sv+Yi5t53MX3/wHJ+2BLjgb9/kqsc/o2njUo44ayZfKuxk4e/nWsV1CtIZdc1lvF+v+OtHW6hcsY5gexPe3GJKKoZz7qQhTCjwojYsou6TNTSsbWK7P0JDKNItMcskozCNzCEZpJXk4yoswlFQQiwtl1haLh2hGL5wjOZAmGa/peW3+MK0B8L4AxErMSsUtVo4SsxOzOqi2cd6NlpLJlWjNU1qiFIpN6BARBYntRu7vV0psC1pvdLu63Efu3Z4K5Cf4rG7TV/RO1VYev4FdNXw24Hv7+3JNRqN5oBEpZz53KCUmjqQl9Lf9KXpLwWWisgT9jeQRqPRHPRI6oN+X2wHhiWtl9l9Pe1TKSIOIBsr+TWVY3ebvuSdZ+zFz0RkWVJbLiLL9vbkGo1Gc+ChIBZNrfXNImCMiIwUERfWxOzsbvvMBq6xly8G3lFKKbv/cju6ZyQwBvh4b++uL3nne/breXt7or1hyOEjuev2B3j4oVt59rizmFfv4/7Xb2fG/e8T6mzlf79xDI2/vZk5m1uYke9l4m3/w9+W1LD2vytp3rwCd2YeIyaP48opZeRWf8a6199n/fomGkJRTIGhHifFw7MpOCyPgiPHYpYfTqOks7Gpg/W1HWyr77Ri9FubCXW2Egn5E9orJBmtJcXoGw5XIkbf4TIxTEnE6Ltc8bh8S8NPNlqLx+U7TctkzRCxdf2dY/Tjen5yYfR4jH4y8X3i3/BxvX5XMfrdj0+mNzl+X+r5ALdf/Q/uW/4P8m56mLO/cS3NN19BVSDMldOH8tmkr7Do/j+QXzGFP155FNv+8B3e2trKMK+TyddNJzDtS/zl2eWsWFZLy9bVGA4XOeVHcOThxZw0Io/M5s9p/mQhtUuq2NrkpyEUxR+1nv4yHHaMfpqTjKEZpA/JI6O0ELOwFLKLiKXlEjbddPgitAQitAbCtIciNHWEaPWH6AhECAejhIORHUZrkRjRSKTXGH2gi56fHKOfKlrnTxGldkfe6eOtVEREbgLmAibwiFJqpYj8ElislJoN/B14XEQ2AE1YXwzY+z0DrMKaQ/323kbuQN/yTrW92AD4lVIxERkLjANe39uTazQazYFIP8o7KKXmAHO69f08aTkA9BgCr5T6FfCrfrsYUg/ZXAB4RKQUeAP4KvBof16IRqPRHDCoWGptEJLqoC9KKR/wJeAhpdQlWAkDGo1Gc5ChDupBP9UauSIixwFfwcoeA0uf0mg0moMLxaAd0FMh1Sf9m7EycF+0JxdGAfMG7Kq6sboxSunRM/nCB/ezoMHHV44t5dmic1kx53kmn/9FvppTzez73sVrCqd883i2jJrJX2avomnjUqIhPwXjjuXLJ5YzvdCk6T8vsHneFj7vDBOKKfJcJqMzXJQcWUzh5FG4xh5FOH8UVR1h1jV2srq6jfYmP51tPoIdTUQCnUSD/p0rZjldmC6PNXnr8uLwZuB0uxKTt/FqWQ6naRutGQmjtfi60zAS5mrxCVynIbbPh9jbdyRm7ZigtRKzejNa64lUjdZSZV9P4gJ86agSZs4VnOlZPD/TxZ//uZzrLhnPjOf+wtf/70OC7U18+fKTmLD1bd55ZBH+aIxTppQw9Ppv8+zKOj75uJLqVZ8RDfnJKCmnbEwR5x5eTEWmIrR0ATUL11C7tpGqQAR/NEZUgcsQshwmJR6TzKEZZJVlkTm8CGfRUByFpUS9uQQMN+2hGB3hGM1+KzGrqSNEi52cFfCH7UncaJcWi+yYxI3a1bOSE7PixHpIwuorMUtP4u4OColGUmqDkVStld8F3hWRDBHJUEptBPaJw6ZGo9Hscw71J30ROUJEPgNWAqtE5BMR0Zq+RqM5+FAq9TYISVXT/wvwA6XUPAAROQX4K3D8wFyWRqPR7EcO4if9VAf99PiAD6CUmi8i6QN0TTvhb21m+b3n8rPMH/LdG6ZQ/vu/ccnXHid7+Hie/taxLLzkCyxtDXDl9KGUfO9Orpu7ls0ffwhAVtlYJk8v49KJJbDwWTbO+YzltZ00haJ4TWF0uouiSYUUHz0O7+gxqLIJVPtirGnoZOX2NmrrOmlr8hNsrSfc2UrY39Gj0Zppm605XF7bcM1t6fguI5Gg5XSbuBNGa44uSVlep5konGIYOwqomEY3Ld8uyCzd9PxdeXv3lJjV+747J3Z12Z7yv9rAM2TOXD4862b+8+w9vHjsKYzPdFPxjxf40dwNrJ/3Ioed8WV+f+4YFp3xbRY1B5iR7+Wo753PGk8Ff39rEfVrFuNvrsGdmUfJYRM5Z2opxw/Lxvz8A2o/WEzNkjo2dYZpCkWJKjAFsp0GhW6TvHwvWWWZZA4rJq10CI7i4cTS84ml59Puj9IZidHkCyc0/caOEK2+EL5AhFDQ1vFDMWIRKzErZmv4sUiIaHJyVjejtbie31tiltbu+4f+jNM/0Eh10N8oIj8DHrfXrwI2DswlaTQazf6k/zJyD0R2pzB6IfAC8DxQYPdpNBrNwYVSEIuk1gYhfdXI9QDfBCqA5cAtSqnwvrgwjUaj2R8Ih7a88xgQBt4DzgHGY8Xs71OGlpUwf9wxTM52w12PctpDi2nZuppf3/sj0v75M55/bxtTcjwc85tv8u+twrzXl+JrrKJg7DSGjhvFTSePZljrGja+9DprF1ezzR/GFBjmdTJieBZDpo4kfdIUzNKxtHgK+LymkxVVbayvsmL0/S1NBNubrGLoSXo+kDBai8foJxdDdzhNnG4HTrcD0yG47Jh8r8vRQ4z+jsIpVtEUIxGn35vRWrKe31cxdDh4jNbiHH/tHzn+6msY+fAPeL6+kz/852ec/eeFLJv7LtnDx/PQN4+l8bc389qiKko8DmZ89Sjk/O9y70ur2fTJCvzNNRgOF7mjJjNpUjHnjy+msHMr7R++w/aFG9lS3U5tcEfhFK9pUOByMNTrJKssi+yRRWQOL8ZRMhzJG0IkPZ+2UIy2UIzOUJQGX4imgBWj39QZpMUXJui34vMTun48Pj+FYuhxdDH0fUDs0B30JyiljgAQkb/TD7aeGo1Gc2AzeMMxU6EvTT8h5exuERURGSYi80RklYisFJHv2f15IvKmiKy3X3P34Lo1Go1mYIjbMByk3jt9DfqTRaTNbu3ApPiyiLT1cWwEaw5gAnAs8G27uvutwNtKqTHA2/a6RqPRHCAoJBZJqQ1G+vLT32NTNduLv9pebheR1VhFfS8ETrF3ewyYD/xkT8+j0Wg0/c4gfYpPhVTj9PcKESkHjgIWAsVJxVlqgOJejrkRuBGgNDuDNzoK+P3nLzH69tep+mQux1z5Vb6Xv40/3TkHlyGcd8upbDr8In7/h/eoX/MR6YXDGD9jIhccXcpJhYrGfzzB+lfXsqItSCimKPE4OCzHw9BppRRMn4wx6ijCOWVsbgiyrKaNpdtaaKnvpKOlk0BbPWFfWxejNTHMnYzWnJ6MhNGa0+3A5bZN1lwGpmngdZlkepw7TeJ6HGaiWtaOhCxrItbq69lora9J3DjxPkjdaG1XyV7J7K9JXACnN4O3z1J8d+J7fOe6I3ks+3QWPvVbAG7++beZvvk1HrnvXVrDUa46ZQQjbv4Js5bUMH/+Rpo3r8DhySC9aBgjjxjG5VOHcVhGlPD8N6lcsIztKxvY5o/QGrb+82c7TbIcBiUek+wRWeSMzCVzeBGu0hE4iocTySzEb3ho80dp9IXpCEVo9oepbwvS2BnqYrSWbLYWjUQSn6t4YlZ3o7WeqmVpo7UBRKlUSyEOSlKN099jRCQDK7b/ZqVUF0nIrgPZ44yJUmqWUmqqUmpqfrp3oC9To9FoElhftn23wciADvoi4sQa8J9QSr1gd9eKyBB7+xCgbiCvQaPRaHaPfi2M3iupBLWIyJEi8l87GGaZiFyWtO1REdkkIkvsdmQq5x2wQV8sreDvwGql1L1Jm5Irv18DvDxQ16DRaDS7jWKfDPqkFtTiA65WSh0OnA3cLyI5Sdt/pJQ60m5LUjnpQGr6M7Bq6S4XkfjF3A7cDTwjItcDW4BL+3qjqqpW7vzLDcx8oYXqz96idNq5vHnTsbw58XhWtwf5xoVjyf3hfXzl4Y/Z+OFbmC4v5dOO5YdnjmV6aSaRNx5i9VMLWVTbSWs4RrbTYGyGi9LpQxh6wiRcR5xAa0Yp9e1hlta28dmWZupqOmhv9hNoriHc2UYk6O+SmGU4XIhhJgzWnJ4M+9WDy+3A6TYTur7bbZmrZXoceF079Hyvy+xitOY0rMIpZpKWHzdZ68loLa7nA130fLr1Ja55l6Zsu9bzezo0VT1/oFjyyA3cW3oU55Zm4fjN49xx3YOk5Q9lwqnH8/+mOHnrhPtY2hrgvCGZTPn5jbwbHsqsVxZTs+J9APIrplBUXsLlM8o5aXgWsvRVqt7+kO0fV7OhI0R90IrOyHAYFLhM8lwmhSUZ5I7KIWvkENLLR+AcWk40s5iIN49WX4Rmf4QGX4iOUJSGzhCNHSEaO4J0+MKEglFCwQjhQJRIKEokFCZqf67iZmoJY7VIaCejNa3n7xuUUqjwPjEe6DOoRSm1Lmm5SkTqsCxxWvb0pAM26Cul3qf3JM6ZA3VejUaj2Tt2ayK3QEQWJ63PUkrNSvHYlIJa4ojIdMAFfJ7U/SsR+Tn2LwWlVLCvk+6T6B2NRqMZNCi1O7+SGpRSU3vbKCJvASU9bLqj6ymVEpFe04Dt+c/HgWuUSsST3ob1ZeECZmH9SvhlXxesB32NRqPpTj9F5iilTu9tm4jUisgQpVT1roJaRCQLeA24Qyn1UdJ7x38lBEXkH8APU7mmAQ/Z1Gg0msGF6lbEpve2l/QZ1CIiLuBF4J9Kqee6bYtHQQpwEbAilZMOiif9whwPD46+lg9/eDcnfu1r/N8lk1l9xYW8tLGZL4/L54gHH+A7r65l6X/mE/F3MPzYc/nmBROYWRSFJbNZ/uhcPlvdSFUgkqiWNfrIYspOnkja1FMIDZnA53V+NrX4WbS5mU3b22mp78TXWEugtX6nalmGw2UlZTmsxCyn15rEtRKzHDg9ZpfJXG9StSyvc8ckrsth4HYYeEzrdYer5o6ErPhrfALXNHa4a8aTsrpjSNdJ3O7JWt0Ts/qsprXn/3T2++/lG/TCkiknAHDGsjcYf9sb+BqquOOum/j2MWUsufR8XtnUzJQcDyff/WW2TriAXzz+CZsWfkC4s5W8UZOpOHoUMw4r5AtjC8jc+jHVb7zJ1gWbWFvvozYYIarAawoFLpPhaU4ys93kjsohp2Io2RUjcJaORuWVEc0sojkQpTUYpbYzRF1niM5QhOqWAPXtAVo6QoQCEUL+MOHu7prxFtvhttlbtSxIfcJWT+LuBfHonYGnx6AWEZkKfFMpdYPddxKQLyLX2sdda0fqPCEihVj/RZdg2eD3yaAY9DUajWafsY+id5RSjfQQ1KKUWgzcYC//C/hXL8eftifn1YO+RqPRdOHgtmHQg75Go9Ekc5B77wyKQT9SNpK7bn+ACedczNyLi6i8/zs8NHsdpxamcepTv+G+DU5efPINOmo3UzL5VK68YDzXTCrC/+9fsf3dpXzy/jbWdQQxBcrTXIwbm8ewk8eRfdzJRIYfxYbmIIurWtlU38mqLc001rTT0VCHv7mGUGcb0dAOozXD4bIqY7m8GA4nDm8GDk8GzvRs3F6nreU77MQsBxkeB5keBy6H2cVozesy8ZhGolqW0zRw26Zr8SpZydWyTFuXT66WFTdZg52rZSXr+XGSpfXBWi0rmbe2tnLP0keYfu8SKhf9h4u+83VuHVLFplt/yhNvbGSY18l5t5xK6Is/5kdPL2Pl/I/wNVaROWQ0I4+eyNdPHsWUoVmUtm2gae7LbHl7DWs2tbLNH8YfVbgMIddp6fkFw7LIKEoj97Ah5IwdhnP4WCguJ5pVQksYWgJRqtuD1HUGqW0L0BGI0NQZpLEjRNAfIegPd6mWFQ35E4lZ0XjFrOjOE4VxPT++Lc6uNHut5+89g9VXJxUGxaCv0Wg0+w79pK/RaDSHDEopVGSf2DDsF/Sgr9FoNMnsu5DN/cKgGPQ/31zDyK/OZOFtxzN3wknMq+lgcraHi566lSci4/m/v71N08alFIydxhcvPJLvzxhObPb9fPbnt9m2uYUVbZYdRXmai0mjcxh5xngKTj0VNfZ4NnUKC7c18+GGBiobfDRWd9BeV2/p+b6uer4YJobDhcPlxeFJx3C6EoVT4lq+y+vA7XHidJuk2Xp+hseJyzTsZUdCz3c7TCtO32HYZmtWXL5pkIjPNw1J6Plxw7Uuy/bfKFnPJ6kPdtbpUy2cciDr+QB3vXYHM+cKy199hhnXXMsTp6fzn+Nu4IO6TrKdJpfeOI3cH97HTS+t5qPXF9JWuY60/KGMnDaVa2dWcP5h+XibN9P2+lNseOVT1qyqZ7MvREckhimQ5zIZme5kSFkmBYflkVaUTd64EbjKx2GUjCSSNYTWqIMmf5TqjiA1HUGqWwNUtwboCISpawsS6AwTDIQJ+iM7CqiEgsTCoZ30/LjxWnLhFOiq53fX67V+PxBoeUej0WgOHRQJR9ODET3oazQaTRdUv3nvHIjoQV+j0Wi6o+UdjUajOURQipiO3tm/ODzpLL/3XOZPOp5XKtuYmOXm6ie+x8sFp/Oze9+mdsUC8iumcN6Xj+Pnp4/GNfchPrn/VT5Y1UBDKEIophid7uLoUTmMPnsCxWedAYefwqagiw+3tfDuunrWbWymsy1Ia20DvsbtBDuaifg7ukzimi4vTm8GDk96wmTNSspy4/I6cXsdCaO1jDRnYhI3066cFZ/ETXeaO03iuh3GjslbkV1O4go7V8pKnsTt3g87m6zB4J7EBbhwwzg+/OffmX75V3nj8lLePukSXqlso9BtctX1Uyi96y/c/Opa5jz/AU0bl1qTuMfM4PpzDuOywwtxf/YKnWuWse6FhaxdWse6jhCtYWsSt9DtoDzNSenQTAonFJA/sZz0knw8FRMwS8cSyR1GGx6aAhFrArc9SHVbgOqWAHV2cpavM0QwECbUbRI3GvRbyVlxs7WEyZo1iRs394slJWxBapO4emK3H1AKFdXyjkaj0RwSKIUe9DUajebQQWkbBo1Gozlk0E/6+5+Jw7KYP+4YXt3ayrcuGc+4Gy/lmbwzuP13b1C7YgEFY6fxpUtn8MszK/D8508s/v1LzF9WR1UggikwOt3F1DG5VHxhIsXnnAUTT2NjwNLz562pY93GZhqq2gi2t6Sk57vSs3GmZ2M4XAk935PuTCRlZaQ5yUlzJvT8DI+l6aei58eTs3al55uGHPJ6PsC8v/6d46++hrcuLeLNY7/Ey1taOb8si/EXT2Tor//O/7y8hteeXZDQ80cfdwI3njeeyycW4f30ZbY+/QKNa+tZ8Ul1j3r+8NJMio4opHDyKLLGjcHML8EsOyyh59f7IlS1B9neFqCyxU91S4DqVj9NbUHCwWhCzw/6w7vU8+MavtbzDwyUUkRDeiJXo9FoDhm0vKPRaDSHCgd59I4ujK7RaDTdUNFYSm1vEJE8EXlTRNbbr7m97BcVkSV2m53UP1JEForIBhF52i6i3ieD4km/adka3qCE7//PdLz/7x88uKKG3/7qeZo2LqVk8ql87Ypp3HbSCIL//hUf3juXdz9voj4YJc9lUux2cNT4fCrOn0zhWecQG38y69rh/S1NzF9Tx+ebmmmsbqejdhMRfwfB9uZei6Yk6/mutHQcTtMqnGKbrLm9DjK7xedneHZo+t1N1uJFU3oqgt6XyVpysfOeiqbE9f84B5ueD/DF732Tf0/38dxRX2ZevY9Ljyji5Kd+S8uw6Vz+xFLef3k+bZXryBwymrEnHMt3zjmML43Lh/f+zcZnXmHDnM/Z5gvzeadlsuYyrCLoFRkuho7IpviIQgomjSbzsLG4KiYRS8shklNGc9RBoy9CZVuA7e0BKpv9ltFai5+WdstkLRKOdjFZCwd8iaIpkZA/EZtvmaztXAS9Nz1fa/kDj1L7LHrnVuBtpdTdInKrvf6THvbzK6WO7KH/HuA+pdRTIvIwcD3w575Oqp/0NRqNphuxaCyltpdcCDxmLz8GXJTqgWI9uZ0GPLe7xw+KJ32NRqPZZ8QUsVAk1b0LRGRx0vospdSsFI8tVkpV28s1QHEv+3nsc0SAu5VSLwH5QItSKn6hlUBpKifVg75Go9Ekodit6J0GpdTU3jaKyFtASQ+b7uhyTqWUiKhe3maEUmq7iIwC3hGR5UBrqhfYHT3oazQaTTL9GL2jlDq9t20iUisiQ5RS1SIyBKjr5T22268bRWQ+cBTwPJAjIg77ab8M2J7KNQ2KQT8UU9z58BWsOeuHXPPzN6ldvZhAawOjTrqQ266ewpXDotT99mY+efgDFjT46IjEGOpxMH1oJnljchl93tHknH4B/uFTWVHvZ/7GRhasradqawtNVY1WQlZrAxE7cSZOfBLX6Um3qmOl2ZO4Xi9urxOHy8DtsSdyvU6y05xkepxkuB2JKlkZHgceh4nTFHsi15rMjVfK8iQbrRmCgT2Ra7BjWayJ1O6TuMkJWdBtcjd+D3s5gWvt2/fs7L6cwI3zj8wF3Dt9FlWBMN+4cCwT//IX7l4RZs7sj1jxxlv4m2vIr5jC4Scfya1nHcZJ+WEis+9n7ZPzWPdhJSvagrSGY4RiCq8pDPU4qchwUlSRR9ERxRRMqiDtsAk4yycQyS0j5smmwR+lwR+mss1KytrW5EtM4nZ2hgh0hgn4wkQjMcLBCKFgxErGSk7KshOykqtkxSdx48U79CTu/mUfhWzOBq4B7rZfX+6+gx3R41NKBUWkAJgB/Nb+ZTAPuBh4qrfje0JP5Go0Gk0yCmKxWEptL7kbOENE1gOn2+uIyFQR+Zu9z3hgsYgsBeZhafqr7G0/AX4gIhuwNP6/p3LSQfGkr9FoNPsKxb5JzlJKNQIze+hfDNxgL38IHNHL8RuB6bt7Xj3oazQaTTJKEQtr7539ypAJI3hw9LU8cPOjtGxegSe7kGmXXsYfrzyKiQ0fs+b7D/Dea5+zoi2AKcLELDeTJxRQccGRZI8dievYL1CXPpxFm1uZv76BTzY0UFfZRltNjaXnd0vIEsPEcLhwuK2ELCsZK9sumOJMJGRZyVkO3G5HwmAt22slZ3ldpqXn2wlZTlPsZKwdRmvJCVnJBmvJyVlC73p+TwlZcPAarHXnjsseZKjHya2/Pg/1jbu58MmlLJw9j876bYhhMuyYL3DOGWP4zonljOlYR8Mjj7P2+cWsWN2YSMgCyHYaDPM6GZ3roXBCAUWTh5M3cSTuiklI6RjCdkKWrzNCTUeIyrYg1e0Btjf5qWz2UdcWtLX8EEF/hJA/TDQaIxIKJ7T8SMhKzFLRaELPj0XCOyVkgdbz9zsHucvmgGn6IvKIiNSJyIqkvpTSjjUajWb/ofaJDcP+YiAnch8Fzu7WF087HgO8ba9rNBrNAYNS+ywjd78wYIO+UmoB0NSte4/TjjUajWbfoOxQ2r7bYGRfa/qpph0jIjcCNwK4sotYefsDOL0ZTLvsKk4/amjCYG1+N4O1abkeDjtzFOXnn4jruC8QzSljdTu8v6Z+J4O1YGsDoc7WROEK2LXBmttjFUuJF0E3TaNXgzWv0yTNaZmruU0D05BeDdZMEUxjh5YPqRmsddfpezJY25WWDz3r+Qe6lh/n/AmFnPzUb3k2PIZf/O/bbP5wLgDphcMYc/wxfPcL4xIGa+tsg7VPm/3UBiNElaXlp5tGF4O1/MNHkjVhHK6KSURzh+FPL6TeF6GuM0hrINKrwVrAFyIciBIKRggHrTj8VA3WtJZ/gBGDWOjg/Rvvt4ncPtKOsf0rZgGkl45Vg/M7VaPRDDYUatBKN6mwrwf9lNKONRqNZr+hQMV6fR4d9OzrjNx42jHsRtqwRqPR7EtiUZVSG4wM2JO+iDwJnIJlPVoJ3ImVZvyMiFwPbAEuHajzazQazZ6gDvI4/QEb9JVSV/Syaae0477wtzQz6sKZ3HL1FK4/zANrPmDlFd9lwTtbWN0exGUIU3I8HHFUMRXnTyHvjPMIVcxgaX2AzZs6mbeugSUbGmmoaqOtpgpf43ZCnW07VcgSw8TpzcDRzWDNk+6ykrCSzNUyPA7cDoPsNFcXgzWvy5rAjZurOc0dE7lOQ6y+bhWyupurQWoJWV2Sr4gft2N7MgdLQlYy5e+8zczHP2Xp67PorN9GTvlEJpx0NMeNLeSbxw6nrP4zan77/1j30hKWfd7CZl8If9QyVyt2O6jIcJGZ7aZoQgEFE4eRf0QFropJMKSCUE4ZjUFobAmxtTVATXuAtmCEyiY/Na1+alsCBHxhAp2hRIWsZHM1FYsmErJ2TOKGd1khC3qezO2+TTPAKIUapE/xqTAoMnI1Go1mn6EgqqN3NBqN5tBAAbGDeCJXD/oajUaTjJZ39j8lpcUsv/dcQk/cxYLr57Klup1PWwIAjM90c9T4fCrOn0zhWecQG38yq9rh/SU1zF9TR02jj4bt7bRUV/dormY4XBgOF05vBobD2au5mttjJWQlJ2O5TKNrsRTbXM3tsEzVkpOxTIMezdUSCVhJy5CauVpPyVjJ+3Tvh4NDy48z/WsP0la5jozicqZ8+Uq+fe44Lhmfj7N2LU3//BkfPb+YlSvrWddhmau5DGGox9ElGctblEvBpNG4Rh2OWTaWSO5wmqMOGlujVLYFuiRjdQTCVLcEupirhYN2C/i6JGMpO+lqV+Zqven3fa1rBh4dp6/RaDSHCFb0jn7S12g0mkMDPehrNBrNIYRSRMMHr6Q2KAb9In8974yZzoLaDlrDljY7OXvnuPxl9QHe/ayBeavrqNzSQlN1M+HO1l7j8rsXPTccrl3G5ed0i8l3OYxe4/K7Fz2Px933FJffPSYf2GVcfl9FUrpvSz6mO4NRy49jOFwcf/U1/PDscZw51CQ673HW/+5NGtY07hSXX57mpCLDRfGoHLvo+WjSx47DkV8CQyqI5JRRH4TGtghbWzuoaQ+wLclYra09SCQc6zUuP7noeSIWv4+4fG2sdmCiYJ9k24pIHvA0UA5sBi5VSjV32+dU4L6krnHA5Uqpl0TkUeBkoNXedq1Saklf59WF0TUajSYZtc+KqPRZX0QpNU8pdaRS6kjgNMAHvJG0y4/i21MZ8EEP+hqNRrMTKqpSanvJ7tYXuRh4XSnl25uT6kFfo9FokrAqZ+0Tw7WU64vYXA482a3vVyKyTETuExF3KicdFJq+RqPR7DN2byK3QEQWJ63PsmuBACAibwElPRx3R9dT7rq+iG1FfwQwN6n7NqwvCxdW7ZGfAL/s64IHxaC/vbKFt8w0xme6mTx1CHkV+Qw7fybm0WdT5Shk3vY25r26lmUbGmnY3kZ7XXVi8jYWCSUqY4lhYrq8CVM1V3o2Dk8G7swcXF4npmng9joSlbHSvE5y0pxkeJw9mqqZIonKWJ5uk7jdTdXiE7OJZXo3VYOdJ3Xh0DRV2xWL/34jpTWLqX7qp7z/4lKWb25NTN4C5LlMxmc6GVGYRvERhRRMHE7exDG4Rh2emLztiAn1vig1NVYi1rYWf8JUraEt2MVULRqN2YlYga5VsXowVQP6rIzV20StnsDdz+xeyGaDUmpqr2+l1Om9bROR3akvcinwolIqnPTe8V8JQRH5B/DDVC5YyzsajUaThIJ9NZG7O/VFrqCbtGN/USDW099FwIpUTjoonvQ1Go1mn6H2TcgmvdQXEZGpwDeVUjfY6+XAMODdbsc/ISKFWD/qlwDfTOWketDXaDSaLuwbwzWlVCM91BdRSi0Gbkha3wyU9rDfaXty3kEx6Bdmubnzd1eQddoFtA+ZTL0vwguVrbw9r55VGzfSsL2Njrrt+BqrCHW2Eg35E8eKYeLwZOBwexM6vjMtG1d6ZkK7jydhOZwmGUmGajleJ16XaRmqua2iKfEkLLfDxBR61PHjxmnxJCzTFtHiOr6ZpMnvylAtfkyX9V2YqSXv352DRcdPZu2Mk3l6Wzvb/GFCMSsJa6jHSZ7LYMSQTAoPL6BwUjk540fjqpiEKh5NJKeUKl+EJn+ErZvb6QhG2N4WSOj4dXZxlJA/TNAfIegPEwlHifg7ULHojiSsXRRH6a7hJy/rJKwDH6UgprQNg0aj0RwSKCCk/fQ1Go3m0CGqn/Q1Go3m0EABB7HJ5uAY9GPDR/Hg6GtZ8EY9NVvn4WsP0lG3HX9zTaIoSpy4aZrTk44zPRvT4epVw3d7nWSnOcm04/DTXOYuNXynYZuo2fq9IdKrht89Dh/6LnDeU1GUPSmIAgenht+dOeubGOpxcmphGsWH5VN0RAkFkypw5ed10fDr4xp+U4Dtm2vY3uynstlPXVsAfyDSq4Yfi4RSMlLrLQ6/+/Ku+jQHDkrpJ32NRqM5pNBP+hqNRnOIoFD6SV+j0WgOFazonf19FQOHHvQ1Go0mCa3pHwCs31LLXbc/sFPSlenyWqZp+UOtpKv0bFxp6V0mah1OE6fbSrqKm6dlui3jtAyPA6/TTEzYOuLGaYZlpBZPtuot6UrEmlw1JbXKV/F+6B/ztFQna633T3nXQcOvX/ohrlGHEysoJ5hRTKM/yvrOMK3xhKuVfiqb11LXFqCpLYi/I0TQHybkt6pehYPW5GyXylf2pG0sEkLFYntV+WpX/ZoDG63pazQazSGCFbJ58I76etDXaDSaJHScvkaj0RxCKKVtGPY7pstD6dEz8aS5cHsdGA4Dt8dKtMq0DdKyvS4y7QInGR4H6S4HHoeVQOV2WFp9d2O0ZK0+boqW0Od70Op36O89a/V9JVcl98fZG4O0g1Gn3x2uqDmalvVBAp0bCPhWEQ5ECQbCqJgiHPB1LXSSMEfbe61e6/QHP1re0Wg0mkMEBRzEEZt60NdoNJqu6OQsjUajOWTQE7kHABNH5PHBvefu78vQHGDMeXDW/r4EzUGIDtnUaDSaQ4iDPXrH6HuX/kdEzhaRtSKyQURu3R/XoNFoNL0RVam1vUFELhGRlSISs4uh97Zfj+OliIwUkYV2/9Mi4krlvPt80BcRE3gQOAeYAFwhIhP29XVoNBpNT8TlnVTaXrIC+BKwoLcd+hgv7wHuU0pVAM3A9amcdH886U8HNiilNiqlQsBTwIX74To0Go1mJ+ITuQP9pK+UWq2UWtvHbj2Ol2IlAJ0GPGfv9xhwUSrn3R+afimwLWm9Ejim+04iciNwo70aTPN6V+yDa9tXFAAN+/si+pGD7X7g4LunQ+l+RuzNGzcQmvsXthSkuLtHRBYnrc9SSvVnhEFv42U+0KKUiiT1l6byhgfsRK79h5sFICKLlVK9al6DDX0/Bz4H2z3p+0kdpdTZ/fVeIvIWUNLDpjuUUi/313l2h/0x6G8HhiWtl9l9Go1Gc1ChlDp9L9+it/GyEcgREYf9tJ/yOLo/NP1FwBh75tkFXA7M3g/XodFoNAc6PY6XSikFzAMutve7Bkjpl8M+H/Ttb6WbgLnAauAZpdTKPg472LJw9P0c+Bxs96Tv5wBDRL4oIpXAccBrIjLX7h8qInOgz/HyJ8APRGQDlsb/95TOqw7izDONRqPRdGW/JGdpNBqNZv+gB32NRqM5hDigB/3BatcgIo+ISJ2IrEjqyxORN0Vkvf2aa/eLiPyffY/LRGTK/rvynhGRYSIyT0RW2Wnj37P7B+U9iYhHRD4WkaX2/fzC7u8xrV1E3Pb6Bnt7+X69gV4QEVNEPhORV+31wX4/m0VkuYgsicfCD9bP3IHEATvoD3K7hkeB7rG+twJvK6XGAG/b62Dd3xi73Qj8eR9d4+4QAW5RSk0AjgW+bf9bDNZ7CgKnKaUmA0cCZ4vIsfSe1n490Gz332fvdyDyPazJvjiD/X4ATlVKHZkUkz9YP3MHDkqpA7JhzWjPTVq/Dbhtf1/Xblx/ObAiaX0tMMReHgKstZf/AlzR034HasMKDTvjYLgnIA34FCvLsQFw2P2Jzx9W5MRx9rLD3k/297V3u48yrEHwNOBVrEqcg/Z+7GvbDBR06xv0n7n93Q7YJ316Tj9OKc34AKVYKVVtL9cAxfbyoLpPWwo4CljIIL4nWwpZAtQBbwKf03tae+J+7O2tWCFyBxL3Az9mR6W/XaXpD4b7AcsG5w0R+cS2ZYFB/Jk7UDhgbRgOZpRSSkQGXaysiGQAzwM3K6XaJKky+2C7J6VUFDhSRHKAF4Fx+/eK9hwROQ+oU0p9IiKn7OfL6U9OUEptF5Ei4E0RWZO8cbB95g4UDuQn/YPNrqFWRIYA2K91dv+guE8RcWIN+E8opV6wuwf1PQEopVqwMhuPw05rtzclX3Pifuzt2Vhp8AcKM4ALRGQzlgvjacADDN77AUAptd1+rcP6Yp7OQfCZ298cyIP+wWbXMBsrVRq6pkzPBq62ow+OBVqTfr4eEIj1SP93YLVS6t6kTYPynkSk0H7CR0S8WPMTq+k9rT35Pi8G3lG2cHwgoJS6TSlVppQqx/p/8o5S6isM0vsBEJF0EcmMLwNnYvnPD8rP3AHF/p5U2FUDzgXWYemtd+zv69mN634SqAbCWNri9Via6dvAeuAtIM/eV7CilD4HlgNT9/f193A/J2Dpq8uAJXY7d7DeEzAJ+My+nxXAz+3+UcDHwAbgWcBt93vs9Q329lH7+x52cW+nAK8O9vuxr32p3VbG//8P1s/cgdS0DYNGo9EcQhzI8o5Go9Fo+hk96Gs0Gs0hhB70NRqN5hBCD/oajUZzCKEHfY1GozmE0IO+Zr8jIlHbSXGl7Xx5i4js8WdTRG5PWi6XJLdTjeZQRw/6mgMBv7KcFA/HSpQ6B7hzL97v9r530WgOTfSgrzmgUFbK/Y3ATXZ2pSkivxORRbZP+jcAROQUEVkgIq+JVXPhYRExRORuwGv/cnjCfltTRP5q/5J4w87C1WgOSfSgrzngUEptBEygCCubuVUpNQ2YBnxdREbau04HvoNVb2E08CWl1K3s+OXwFXu/McCD9i+JFuDL++xmNJoDDD3oaw50zsTyVFmCZeecjzWIA3yslNqoLMfMJ7HsInpik1Jqib38CVatA43mkERbK2sOOERkFBDFclAU4DtKqbnd9jkFyw8omd48RYJJy1FAyzuaQxb9pK85oBCRQuBh4E/KMoaaC3zLtnZGRMbarosA020XVgO4DHjf7g/H99doNF3RT/qaAwGvLd84serxPg7ELZz/hiXHfGpbPNcDF9nbFgF/AiqwbIRftPtnActE5FPgjoG/fI1m8KBdNjWDElve+aFS6rz9fCkazaBCyzsajUZzCKGf9DUajeYQQj/pazQazSGEHvQ1Go3mEEIP+hqNRnMIoQd9jUajOYTQg75Go9EcQvx/RXX4CWTX5MgAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#如何生成mask\n# 1. padding mask, 2. look ahead\n\n# batch_data.shape: [batch_size, seq_len]\ndef create_padding_mask(batch_data):\n    padding_mask = tf.cast(tf.math.equal(batch_data, 0), tf.float32)\n    # [batch_size, 1, 1, seq_len]\n    return padding_mask[:, tf.newaxis, tf.newaxis, :]\n#设置3x5矩阵，0都是padding，是零的得到的都是1，其他的都是零\nx = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\ncreate_padding_mask(x)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.544021Z","iopub.execute_input":"2021-08-02T06:36:16.544494Z","iopub.status.idle":"2021-08-02T06:36:16.561072Z","shell.execute_reply.started":"2021-08-02T06:36:16.544444Z","shell.execute_reply":"2021-08-02T06:36:16.559427Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\narray([[[[0., 0., 1., 1., 0.]]],\n\n\n       [[[0., 0., 0., 1., 1.]]],\n\n\n       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"# attention_weights.shape: [3,3]\n#第一个位置代表第一个单词和自己的attention，第二位置是第二个单词和第一个单词的attention\n#看不到后面的词刚好是下三角，使用库函数来实现\n# [[1, 0, 0],\n#  [4, 5, 0],\n#  [7, 8, 9]]\ndef create_look_ahead_mask(size):\n    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n    return mask # (seq_len, seq_len)\n\n#前面看不到后面的padding，矩阵下面全部为0\n# 在mask里，应该被忽略的我们会设成1，应该被保留的会设成0，\n# 而如果mask相应位置上为1，那么我们就给对应的logits \n# 加上一个超级小的负数， -1000000000， 这样，\n# 对应的logits也就变成了一个超级小的数。然后在计算softmax的时候，\n# 一个超级小的数的指数会无限接近与0。也就是它对应的attention的权重就是0了,\n# 下面可以看到\ncreate_look_ahead_mask(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.562762Z","iopub.execute_input":"2021-08-02T06:36:16.563239Z","iopub.status.idle":"2021-08-02T06:36:16.582500Z","shell.execute_reply.started":"2021-08-02T06:36:16.563191Z","shell.execute_reply":"2021-08-02T06:36:16.581164Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[0., 1., 1.],\n       [0., 0., 1.],\n       [0., 0., 0.]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"tf.linalg.band_part(tf.ones((3, 3)), -1, 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.584158Z","iopub.execute_input":"2021-08-02T06:36:16.584639Z","iopub.status.idle":"2021-08-02T06:36:16.594808Z","shell.execute_reply.started":"2021-08-02T06:36:16.584593Z","shell.execute_reply":"2021-08-02T06:36:16.593379Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[1., 0., 0.],\n       [1., 1., 0.],\n       [1., 1., 1.]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"np.exp(-1e9)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.597147Z","iopub.execute_input":"2021-08-02T06:36:16.597773Z","iopub.status.idle":"2021-08-02T06:36:16.605544Z","shell.execute_reply.started":"2021-08-02T06:36:16.597721Z","shell.execute_reply":"2021-08-02T06:36:16.604134Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}]},{"cell_type":"code","source":"#参考原理文档，q是query，k，v代表k和value，q和k做完矩阵乘法后，做mask\n#缩放点积注意力，也叫自注意力\ndef scaled_dot_product_attention(q, k, v, mask):\n    \"\"\"\n    Args:\n    - q: shape == (..., seq_len_q, depth)\n    - k: shape == (..., seq_len_k, depth)\n    - v: shape == (..., seq_len_v, depth_v)\n    - seq_len_k == seq_len_v  这两个是相等的\n    - mask: shape == (..., seq_len_q, seq_len_k)\n    Returns:\n    - output: weighted sum\n    - attention_weights: weights of attention\n    \"\"\"\n    #计算attentions时，我们只用了后两维在计算\n    # transpose_b代表第二个矩阵是否做转置\n    # matmul_qk.shape: (..., seq_len_q, seq_len_k)\n    matmul_qk = tf.matmul(q, k, transpose_b = True)\n    \n    #获得dk\n    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n    #然后根据文档中的公式除以dk\n    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n    \n    #如果mask不是空的话，给scaled_attention_logits加一个mask（缩放）\n    if mask is not None:\n        # 使得在softmax后值趋近于0\n        scaled_attention_logits += (mask * -1e9)\n    \n    # attention_weights.shape: (..., seq_len_q, seq_len_k)\n    attention_weights = tf.nn.softmax(\n        scaled_attention_logits, axis = -1)\n    \n    #根据原理图，v和attention_weights进行矩阵乘法\n    # output.shape: (..., seq_len_q, depth_v)\n    output = tf.matmul(attention_weights, v)\n    \n    return output, attention_weights\n\n#调用上面的函数，去验证\ndef print_scaled_dot_product_attention(q, k, v):\n    temp_out, temp_att = scaled_dot_product_attention(q, k, v, None)\n    print(\"Attention weights are:\")\n    print(temp_att)\n    print(\"Output is:\")\n    print(temp_out)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.607783Z","iopub.execute_input":"2021-08-02T06:36:16.608328Z","iopub.status.idle":"2021-08-02T06:36:16.620066Z","shell.execute_reply.started":"2021-08-02T06:36:16.608282Z","shell.execute_reply":"2021-08-02T06:36:16.618803Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#我们定义一个测试的Q，K，V\ntemp_k = tf.constant([[10, 0, 0],\n                      [0, 10, 0],\n                      [0, 0, 10],\n                      [0, 0, 10]], dtype=tf.float32) # (4, 3)\n\ntemp_v = tf.constant([[1, 0],\n                      [10, 0],\n                      [100, 5],\n                      [1000, 6]], dtype=tf.float32) # (4, 2)\n\ntemp_q1 = tf.constant([[0, 10, 0]], dtype=tf.float32) # (1, 3)\n#可以把这句注释，它的作用是做四舍五入，让结果清爽\nnp.set_printoptions(suppress=True)\n\nprint_scaled_dot_product_attention(temp_q1, temp_k, temp_v)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:16.627660Z","iopub.execute_input":"2021-08-02T06:36:16.627979Z","iopub.status.idle":"2021-08-02T06:36:17.611762Z","shell.execute_reply.started":"2021-08-02T06:36:16.627947Z","shell.execute_reply":"2021-08-02T06:36:17.606429Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Attention weights are:\ntf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\nOutput is:\ntf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"temp_k.numpy().T","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:17.615078Z","iopub.execute_input":"2021-08-02T06:36:17.615896Z","iopub.status.idle":"2021-08-02T06:36:17.624312Z","shell.execute_reply.started":"2021-08-02T06:36:17.615840Z","shell.execute_reply":"2021-08-02T06:36:17.622923Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"array([[10.,  0.,  0.,  0.],\n       [ 0., 10.,  0.,  0.],\n       [ 0.,  0., 10., 10.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"temp_q2 = tf.constant([[0, 0, 10]], dtype=tf.float32) # (1, 3)\n#0.  0.  0.5 0.5 会和temp_v去做平均，因此得到的是550,5.5\nprint_scaled_dot_product_attention(temp_q2, temp_k, temp_v)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:17.626809Z","iopub.execute_input":"2021-08-02T06:36:17.627834Z","iopub.status.idle":"2021-08-02T06:36:17.650071Z","shell.execute_reply.started":"2021-08-02T06:36:17.627785Z","shell.execute_reply":"2021-08-02T06:36:17.648223Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Attention weights are:\ntf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\nOutput is:\ntf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"temp_q3 = tf.constant([[10, 10, 0]], dtype=tf.float32) # (1, 3)\nprint_scaled_dot_product_attention(temp_q3, temp_k, temp_v)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:17.651604Z","iopub.execute_input":"2021-08-02T06:36:17.652029Z","iopub.status.idle":"2021-08-02T06:36:17.675274Z","shell.execute_reply.started":"2021-08-02T06:36:17.651997Z","shell.execute_reply":"2021-08-02T06:36:17.671084Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Attention weights are:\ntf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\nOutput is:\ntf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"#拼起来再来测试\ntemp_q4 = tf.constant([[0, 10, 0],\n                       [0, 0, 10],\n                       [10, 10, 0]], dtype=tf.float32) # (3, 3)\nprint_scaled_dot_product_attention(temp_q4, temp_k, temp_v)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:17.679215Z","iopub.execute_input":"2021-08-02T06:36:17.682047Z","iopub.status.idle":"2021-08-02T06:36:17.704386Z","shell.execute_reply.started":"2021-08-02T06:36:17.681929Z","shell.execute_reply":"2021-08-02T06:36:17.702165Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Attention weights are:\ntf.Tensor(\n[[0.  1.  0.  0. ]\n [0.  0.  0.5 0.5]\n [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\nOutput is:\ntf.Tensor(\n[[ 10.    0. ]\n [550.    5.5]\n [  5.5   0. ]], shape=(3, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"#多头注意力的实现\nclass MultiHeadAttention(keras.layers.Layer):\n    \"\"\"\n    理论上:\n    x -> Wq0 -> q0\n    x -> Wk0 -> k0\n    x -> Wv0 -> v0\n    \n    实战中:把三个概念区分开\n    q -> Wq0 -> q0\n    k -> Wk0 -> k0\n    v -> Wv0 -> v0\n    \n    实战中技巧：q乘以W得到一个大的Q，然后分割为多个小q\n    q -> Wq -> Q -> split -> q0, q1, q2...\n    \"\"\"\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n        assert self.d_model % self.num_heads == 0\n        \n        #这里对应的大Q变小q怎么变，层次\n        self.depth = self.d_model // self.num_heads\n        #神经元个数是512\n        self.WQ = keras.layers.Dense(self.d_model)\n        self.WK = keras.layers.Dense(self.d_model)\n        self.WV = keras.layers.Dense(self.d_model)\n        #这里是拼接，拼接的输出是512\n        self.dense = keras.layers.Dense(self.d_model)\n    \n    def split_heads(self, x, batch_size):\n        # x.shape: (batch_size, seq_len, d_model)\n        # d_model = num_heads * depth\n        #把x变为下面维度，用reshape\n        # x -> (batch_size, num_heads, seq_len, depth)\n        \n        x = tf.reshape(x,\n                       (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm=[0, 2, 1, 3])#轴滚动\n    \n    def call(self, q, k, v, mask):\n        batch_size = tf.shape(q)[0]\n        #经过Q K V变化\n#         print(q.shape)\n        q = self.WQ(q) # q.shape: (batch_size, seq_len_q, d_model)\n        k = self.WK(k) # k.shape: (batch_size, seq_len_k, d_model)\n        v = self.WV(v) # v.shape: (batch_size, seq_len_v, d_model)\n#         print('-'*50)\n#         print(q.shape)\n        # q.shape: (batch_size, num_heads, seq_len_q, depth)\n        q = self.split_heads(q, batch_size)\n        # k.shape: (batch_size, num_heads, seq_len_k, depth)\n        k = self.split_heads(k, batch_size)\n        # v.shape: (batch_size, num_heads, seq_len_v, depth)\n        v = self.split_heads(v, batch_size)\n        \n        #开始做缩放点积，得到的多头的信息存在在num_heads，depth上\n        # scaled_attention_outputs.shape: (batch_size, num_heads, seq_len_q, depth)\n        # attention_weights.shape: (batch_size, num_heads, seq_len_q, seq_len_k)\n        scaled_attention_outputs, attention_weights = \\\n        scaled_dot_product_attention(q, k, v, mask)\n        \n        #因此这里做一下转置，让num_heads，depth在后面\n        # scaled_attention_outputs.shape: (batch_size, seq_len_q, num_heads, depth)\n        scaled_attention_outputs = tf.transpose(\n            scaled_attention_outputs, perm = [0, 2, 1, 3])\n        \n        #对注意力进行合并\n        # concat_attention.shape: (batch_size, seq_len_q, d_model)\n        concat_attention = tf.reshape(scaled_attention_outputs,\n                                      (batch_size, -1, self.d_model))\n        \n        #多头注意力计算完毕\n        # output.shape : (batch_size, seq_len_q, d_model)\n        output = self.dense(concat_attention)\n        \n        return output, attention_weights\n    \ntemp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n#创建一份虚拟数据\ny = tf.random.uniform((1, 60, 256)) # (batch_size, seq_len_q, dim)\n#开始计算，把y既当q，又当k，v\noutput, attn = temp_mha(y, y, y, mask = None)\nprint(output.shape)\nprint(attn.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:31:58.176441Z","iopub.execute_input":"2021-08-02T08:31:58.176792Z","iopub.status.idle":"2021-08-02T08:31:58.219932Z","shell.execute_reply.started":"2021-08-02T08:31:58.176759Z","shell.execute_reply":"2021-08-02T08:31:58.218808Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"(1, 60, 512)\n(1, 8, 60, 60)\n","output_type":"stream"}]},{"cell_type":"code","source":"#定义我们的feed_forward_network，d_model节点数\ndef feed_forward_network(d_model, dff):\n    # dff: dim of feed forward network.\n    return keras.Sequential([\n        keras.layers.Dense(dff, activation='relu'),\n        keras.layers.Dense(d_model)\n    ])\n\nsample_ffn = feed_forward_network(512, 2048)\n#给一个输入测试\nsample_ffn(tf.random.uniform((64, 50, 512))).shape","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:17.843294Z","iopub.execute_input":"2021-08-02T06:36:17.846242Z","iopub.status.idle":"2021-08-02T06:36:17.916224Z","shell.execute_reply.started":"2021-08-02T06:36:17.846192Z","shell.execute_reply":"2021-08-02T06:36:17.914934Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 50, 512])"},"metadata":{}}]},{"cell_type":"code","source":"#自定义EncoderLayer\nclass EncoderLayer(keras.layers.Layer):\n    \"\"\"\n    x -> self attention -> add & normalize & dropout\n      -> feed_forward -> add & normalize & dropout\n    原理对应文档Add & Normalize 标题下的图\n    \"\"\"\n    #d_model 给self attention和feed_forward_network，num_heads给self_attention用的\n    #dff给feed_forward_network，rate是做dropout的\n    def __init__(self, d_model, num_heads, dff, rate=0.1):\n        super(EncoderLayer, self).__init__()\n        self.mha = MultiHeadAttention(d_model, num_heads)\n        self.ffn = feed_forward_network(d_model, dff)\n        \n        self.layer_norm1 = keras.layers.LayerNormalization(\n            epsilon = 1e-6)\n        # epsilon 将小浮点数添加到方差以避免被零除\n        self.layer_norm2 = keras.layers.LayerNormalization(\n            epsilon = 1e-6)\n        #下面两个层次用了做dropout，每次有10%的几率被drop掉\n        self.dropout1 = keras.layers.Dropout(rate)\n        self.dropout2 = keras.layers.Dropout(rate)\n    \n    def call(self, x, training, encoder_padding_mask):\n        # x.shape          : (batch_size, seq_len, dim=d_model)\n        # attn_output.shape: (batch_size, seq_len, d_model)\n        # out1.shape       : (batch_size, seq_len, d_model)\n        #x作为q，k，v  原理对应文档Add & Normalize 标题下的图\n        attn_output, _ = self.mha(x, x, x, encoder_padding_mask)\n        attn_output = self.dropout1(attn_output, training=training)\n        #dim=d_model 两个必须相等，这样x才可以和attn_output做加法\n        out1 = self.layer_norm1(x + attn_output)\n        \n        # ffn_output.shape: (batch_size, seq_len, d_model)\n        # out2.shape      : (batch_size, seq_len, d_model)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        out2 = self.layer_norm2(out1 + ffn_output)\n        \n        return out2\n#来测试，结果和我们最初的输入维度一致，相当于做了两次残差连接\nsample_encoder_layer = EncoderLayer(512, 8, 2048)\nsample_input = tf.random.uniform((64, 50, 512))\nsample_output = sample_encoder_layer(sample_input, False, None)\nprint(sample_output.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:17.921644Z","iopub.execute_input":"2021-08-02T06:36:17.924479Z","iopub.status.idle":"2021-08-02T06:36:18.059631Z","shell.execute_reply.started":"2021-08-02T06:36:17.924417Z","shell.execute_reply":"2021-08-02T06:36:18.058519Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"(64, 50, 512)\n--------------------------------------------------\n(64, 50, 512)\n(64, 50, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"data = tf.constant(np.arange(10).reshape(5, 2) * 10, dtype=tf.float32)\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:28:00.565705Z","iopub.execute_input":"2021-08-02T07:28:00.566098Z","iopub.status.idle":"2021-08-02T07:28:00.573488Z","shell.execute_reply.started":"2021-08-02T07:28:00.566065Z","shell.execute_reply":"2021-08-02T07:28:00.571894Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[ 0. 10.]\n [20. 30.]\n [40. 50.]\n [60. 70.]\n [80. 90.]], shape=(5, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"layer = tf.keras.layers.BatchNormalization()\noutput = layer(data)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:47:17.018131Z","iopub.execute_input":"2021-08-02T07:47:17.018557Z","iopub.status.idle":"2021-08-02T07:47:17.035150Z","shell.execute_reply.started":"2021-08-02T07:47:17.018521Z","shell.execute_reply":"2021-08-02T07:47:17.033457Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[ 0.        9.995004]\n [19.990007 29.985012]\n [39.980015 49.97502 ]\n [59.970024 69.96503 ]\n [79.96003  89.95503 ]], shape=(5, 2), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"(0.9-1.65)/np.sqrt(0.44)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:01:25.679061Z","iopub.execute_input":"2021-08-02T08:01:25.679453Z","iopub.status.idle":"2021-08-02T08:01:25.686602Z","shell.execute_reply.started":"2021-08-02T08:01:25.679418Z","shell.execute_reply":"2021-08-02T08:01:25.685416Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"-1.1306675421666135"},"metadata":{}}]},{"cell_type":"code","source":"np.sqrt(np.sum(np.square(data.numpy()-45))/10)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:41:45.043629Z","iopub.execute_input":"2021-08-02T07:41:45.044017Z","iopub.status.idle":"2021-08-02T07:41:45.052266Z","shell.execute_reply.started":"2021-08-02T07:41:45.043967Z","shell.execute_reply":"2021-08-02T07:41:45.050845Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"28.722813232690143"},"metadata":{}}]},{"cell_type":"code","source":"np.sqrt(np.sum(np.square(data.numpy()[:,0]-40))/5)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:06:04.665294Z","iopub.execute_input":"2021-08-02T08:06:04.665761Z","iopub.status.idle":"2021-08-02T08:06:04.677633Z","shell.execute_reply.started":"2021-08-02T08:06:04.665725Z","shell.execute_reply":"2021-08-02T08:06:04.676095Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"28.284271247461902"},"metadata":{}}]},{"cell_type":"code","source":"sample_encoder_layer.variables","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:18.064883Z","iopub.execute_input":"2021-08-02T06:36:18.067695Z","iopub.status.idle":"2021-08-02T06:36:18.202579Z","shell.execute_reply.started":"2021-08-02T06:36:18.067645Z","shell.execute_reply":"2021-08-02T06:36:18.201262Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[<tf.Variable 'encoder_layer/multi_head_attention_1/dense_6/kernel:0' shape=(512, 512) dtype=float32, numpy=\n array([[ 0.00297762, -0.02380619,  0.0543335 , ..., -0.07150453,\n          0.0506262 , -0.02661466],\n        [ 0.02279303, -0.02753834,  0.03200588, ...,  0.03351516,\n         -0.04166893, -0.07606295],\n        [-0.03144321, -0.01168805, -0.07355859, ...,  0.01345208,\n          0.06550919, -0.00981778],\n        ...,\n        [-0.05629726,  0.07345297,  0.04990254, ..., -0.02335713,\n          0.04594184, -0.06658866],\n        [-0.05553111,  0.02969528,  0.0321468 , ...,  0.03559679,\n         -0.02871855, -0.02720332],\n        [ 0.02919377, -0.00298083,  0.01631236, ...,  0.03926563,\n         -0.02023844, -0.07338355]], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_6/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_7/kernel:0' shape=(512, 512) dtype=float32, numpy=\n array([[ 0.06877569, -0.04757927, -0.007962  , ...,  0.01301298,\n         -0.02355067, -0.06130225],\n        [-0.03938811, -0.04616109, -0.06674887, ..., -0.01987487,\n         -0.0357076 , -0.01134303],\n        [ 0.00447387,  0.0059748 ,  0.01393698, ..., -0.02294958,\n         -0.00399229, -0.03847396],\n        ...,\n        [-0.05474476, -0.00594199,  0.02286474, ...,  0.00678834,\n          0.02986501, -0.06435794],\n        [-0.03713159,  0.07109614, -0.02115136, ..., -0.07512204,\n          0.04911616,  0.00177422],\n        [-0.05428917, -0.00159575, -0.00924893, ..., -0.03504618,\n         -0.02950304, -0.01294246]], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_7/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_8/kernel:0' shape=(512, 512) dtype=float32, numpy=\n array([[-0.00025465, -0.0614673 ,  0.06075255, ..., -0.03960596,\n         -0.05810771, -0.06324999],\n        [ 0.0213089 ,  0.02186521, -0.02327179, ..., -0.03193465,\n          0.01412985,  0.00748001],\n        [-0.04617998, -0.03384536,  0.04516982, ...,  0.07274275,\n          0.06998263,  0.0518455 ],\n        ...,\n        [-0.04165083,  0.06839053,  0.03586718, ...,  0.02000011,\n         -0.06314009, -0.06656306],\n        [ 0.0301666 ,  0.01504242,  0.03388766, ..., -0.01483748,\n         -0.05528453,  0.01197332],\n        [ 0.02423675, -0.00698715, -0.03736833, ..., -0.03966929,\n         -0.07044098,  0.02343281]], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_8/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_9/kernel:0' shape=(512, 512) dtype=float32, numpy=\n array([[-0.00126357, -0.07112163, -0.07532318, ...,  0.02601746,\n          0.05926656,  0.02360243],\n        [-0.01115344, -0.04448133, -0.04672639, ..., -0.05546267,\n         -0.00970635,  0.02423118],\n        [-0.07109406, -0.03809132,  0.06873203, ..., -0.01150232,\n          0.02672479,  0.00216165],\n        ...,\n        [-0.00240995,  0.02408019, -0.0382509 , ..., -0.00449329,\n          0.04999419,  0.02609225],\n        [-0.05674846, -0.05581263, -0.06206611, ...,  0.0302558 ,\n          0.01391786,  0.02762165],\n        [-0.05630929, -0.04974735, -0.06817888, ..., -0.03014727,\n         -0.03042505,  0.01149612]], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_9/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'dense_10/kernel:0' shape=(512, 2048) dtype=float32, numpy=\n array([[ 0.02632378, -0.04127753,  0.03176899, ..., -0.01593417,\n         -0.02800458,  0.01023657],\n        [ 0.04240829,  0.02272607,  0.0377526 , ...,  0.01037236,\n         -0.01867005,  0.0462827 ],\n        [ 0.02216746,  0.01004767,  0.03348462, ...,  0.03635464,\n          0.01995537, -0.02103587],\n        ...,\n        [ 0.02431537,  0.04476358, -0.04216915, ...,  0.02281398,\n          0.0230279 ,  0.02133968],\n        [ 0.04447682, -0.04024589, -0.00697529, ...,  0.01606278,\n         -0.04321285,  0.03999422],\n        [-0.01607622, -0.0059953 , -0.00939126, ..., -0.03888273,\n          0.0213884 ,  0.04252428]], dtype=float32)>,\n <tf.Variable 'dense_10/bias:0' shape=(2048,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'dense_11/kernel:0' shape=(2048, 512) dtype=float32, numpy=\n array([[ 0.04747119, -0.01550258, -0.01460131, ..., -0.04017194,\n         -0.00071563,  0.02319381],\n        [-0.01905321,  0.01607347,  0.04613686, ..., -0.01344392,\n         -0.01589802, -0.03445177],\n        [ 0.02450791, -0.02939462, -0.0066656 , ..., -0.01619416,\n         -0.03208206, -0.01939844],\n        ...,\n        [-0.01336515, -0.04522745, -0.01121302, ..., -0.02214514,\n          0.01543179,  0.00569231],\n        [ 0.03001416,  0.04620026,  0.00691383, ...,  0.01301972,\n          0.02250375,  0.03463352],\n        [-0.02471929, -0.0097758 , -0.00464716, ...,  0.00755734,\n          0.0031228 ,  0.02869412]], dtype=float32)>,\n <tf.Variable 'dense_11/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/layer_normalization/gamma:0' shape=(512,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1.], dtype=float32)>,\n <tf.Variable 'encoder_layer/layer_normalization/beta:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/layer_normalization_1/gamma:0' shape=(512,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1.], dtype=float32)>,\n <tf.Variable 'encoder_layer/layer_normalization_1/beta:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>]"},"metadata":{}}]},{"cell_type":"code","source":"sample_encoder_layer.trainable_variables","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:18.207611Z","iopub.execute_input":"2021-08-02T06:36:18.210616Z","iopub.status.idle":"2021-08-02T06:36:18.343586Z","shell.execute_reply.started":"2021-08-02T06:36:18.210568Z","shell.execute_reply":"2021-08-02T06:36:18.342524Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[<tf.Variable 'encoder_layer/multi_head_attention_1/dense_6/kernel:0' shape=(512, 512) dtype=float32, numpy=\n array([[ 0.00297762, -0.02380619,  0.0543335 , ..., -0.07150453,\n          0.0506262 , -0.02661466],\n        [ 0.02279303, -0.02753834,  0.03200588, ...,  0.03351516,\n         -0.04166893, -0.07606295],\n        [-0.03144321, -0.01168805, -0.07355859, ...,  0.01345208,\n          0.06550919, -0.00981778],\n        ...,\n        [-0.05629726,  0.07345297,  0.04990254, ..., -0.02335713,\n          0.04594184, -0.06658866],\n        [-0.05553111,  0.02969528,  0.0321468 , ...,  0.03559679,\n         -0.02871855, -0.02720332],\n        [ 0.02919377, -0.00298083,  0.01631236, ...,  0.03926563,\n         -0.02023844, -0.07338355]], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_6/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_7/kernel:0' shape=(512, 512) dtype=float32, numpy=\n array([[ 0.06877569, -0.04757927, -0.007962  , ...,  0.01301298,\n         -0.02355067, -0.06130225],\n        [-0.03938811, -0.04616109, -0.06674887, ..., -0.01987487,\n         -0.0357076 , -0.01134303],\n        [ 0.00447387,  0.0059748 ,  0.01393698, ..., -0.02294958,\n         -0.00399229, -0.03847396],\n        ...,\n        [-0.05474476, -0.00594199,  0.02286474, ...,  0.00678834,\n          0.02986501, -0.06435794],\n        [-0.03713159,  0.07109614, -0.02115136, ..., -0.07512204,\n          0.04911616,  0.00177422],\n        [-0.05428917, -0.00159575, -0.00924893, ..., -0.03504618,\n         -0.02950304, -0.01294246]], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_7/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_8/kernel:0' shape=(512, 512) dtype=float32, numpy=\n array([[-0.00025465, -0.0614673 ,  0.06075255, ..., -0.03960596,\n         -0.05810771, -0.06324999],\n        [ 0.0213089 ,  0.02186521, -0.02327179, ..., -0.03193465,\n          0.01412985,  0.00748001],\n        [-0.04617998, -0.03384536,  0.04516982, ...,  0.07274275,\n          0.06998263,  0.0518455 ],\n        ...,\n        [-0.04165083,  0.06839053,  0.03586718, ...,  0.02000011,\n         -0.06314009, -0.06656306],\n        [ 0.0301666 ,  0.01504242,  0.03388766, ..., -0.01483748,\n         -0.05528453,  0.01197332],\n        [ 0.02423675, -0.00698715, -0.03736833, ..., -0.03966929,\n         -0.07044098,  0.02343281]], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_8/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_9/kernel:0' shape=(512, 512) dtype=float32, numpy=\n array([[-0.00126357, -0.07112163, -0.07532318, ...,  0.02601746,\n          0.05926656,  0.02360243],\n        [-0.01115344, -0.04448133, -0.04672639, ..., -0.05546267,\n         -0.00970635,  0.02423118],\n        [-0.07109406, -0.03809132,  0.06873203, ..., -0.01150232,\n          0.02672479,  0.00216165],\n        ...,\n        [-0.00240995,  0.02408019, -0.0382509 , ..., -0.00449329,\n          0.04999419,  0.02609225],\n        [-0.05674846, -0.05581263, -0.06206611, ...,  0.0302558 ,\n          0.01391786,  0.02762165],\n        [-0.05630929, -0.04974735, -0.06817888, ..., -0.03014727,\n         -0.03042505,  0.01149612]], dtype=float32)>,\n <tf.Variable 'encoder_layer/multi_head_attention_1/dense_9/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'dense_10/kernel:0' shape=(512, 2048) dtype=float32, numpy=\n array([[ 0.02632378, -0.04127753,  0.03176899, ..., -0.01593417,\n         -0.02800458,  0.01023657],\n        [ 0.04240829,  0.02272607,  0.0377526 , ...,  0.01037236,\n         -0.01867005,  0.0462827 ],\n        [ 0.02216746,  0.01004767,  0.03348462, ...,  0.03635464,\n          0.01995537, -0.02103587],\n        ...,\n        [ 0.02431537,  0.04476358, -0.04216915, ...,  0.02281398,\n          0.0230279 ,  0.02133968],\n        [ 0.04447682, -0.04024589, -0.00697529, ...,  0.01606278,\n         -0.04321285,  0.03999422],\n        [-0.01607622, -0.0059953 , -0.00939126, ..., -0.03888273,\n          0.0213884 ,  0.04252428]], dtype=float32)>,\n <tf.Variable 'dense_10/bias:0' shape=(2048,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'dense_11/kernel:0' shape=(2048, 512) dtype=float32, numpy=\n array([[ 0.04747119, -0.01550258, -0.01460131, ..., -0.04017194,\n         -0.00071563,  0.02319381],\n        [-0.01905321,  0.01607347,  0.04613686, ..., -0.01344392,\n         -0.01589802, -0.03445177],\n        [ 0.02450791, -0.02939462, -0.0066656 , ..., -0.01619416,\n         -0.03208206, -0.01939844],\n        ...,\n        [-0.01336515, -0.04522745, -0.01121302, ..., -0.02214514,\n          0.01543179,  0.00569231],\n        [ 0.03001416,  0.04620026,  0.00691383, ...,  0.01301972,\n          0.02250375,  0.03463352],\n        [-0.02471929, -0.0097758 , -0.00464716, ...,  0.00755734,\n          0.0031228 ,  0.02869412]], dtype=float32)>,\n <tf.Variable 'dense_11/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/layer_normalization/gamma:0' shape=(512,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1.], dtype=float32)>,\n <tf.Variable 'encoder_layer/layer_normalization/beta:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>,\n <tf.Variable 'encoder_layer/layer_normalization_1/gamma:0' shape=(512,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1.], dtype=float32)>,\n <tf.Variable 'encoder_layer/layer_normalization_1/beta:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>]"},"metadata":{}}]},{"cell_type":"code","source":"class DecoderLayer(keras.layers.Layer):\n    \"\"\"\n    x -> self attention -> add & normalize & dropout -> out1\n    out1 , encoding_outputs -> attention -> add & normalize & dropout -> out2\n    out2 -> ffn -> add & normalize & dropout -> out3\n    \"\"\"\n    def __init__(self, d_model, num_heads, dff, rate = 0.1):\n        super(DecoderLayer, self).__init__()\n        \n        self.mha1 = MultiHeadAttention(d_model, num_heads)\n        self.mha2 = MultiHeadAttention(d_model, num_heads)\n        \n        self.ffn = feed_forward_network(d_model, dff)\n        #因为有两个attention，还有一个feed_forward_network，所以有3个\n        #LayerNormalization和3个dropout\n        self.layer_norm1 = keras.layers.LayerNormalization(\n            epsilon = 1e-6)\n        self.layer_norm2 = keras.layers.LayerNormalization(\n            epsilon = 1e-6)\n        self.layer_norm3 = keras.layers.LayerNormalization(\n            epsilon = 1e-6)\n        \n        self.dropout1 = keras.layers.Dropout(rate)\n        self.dropout2 = keras.layers.Dropout(rate)\n        self.dropout3 = keras.layers.Dropout(rate)\n    \n    \n    def call(self, x, encoding_outputs, training,\n             decoder_mask, encoder_decoder_padding_mask):\n        # decoder_mask: 由look_ahead_mask和decoder_padding_mask合并而来\n        \n        # x.shape: (batch_size, target_seq_len, d_model)\n        # encoding_outputs.shape: (batch_size, input_seq_len, d_model)\n        \n        #按照上面类的注释的步骤依次来编写call实现\n        # attn1, out1.shape : (batch_size, target_seq_len, d_model)\n        attn1, attn_weights1 = self.mha1(x, x, x, decoder_mask)\n        attn1 = self.dropout1(attn1, training = training)\n        out1 = self.layer_norm1(attn1 + x)\n        \n        # attn2, out2.shape : (batch_size, target_seq_len, d_model)\n        attn2, attn_weights2 = self.mha2(\n            out1, encoding_outputs, encoding_outputs,\n            encoder_decoder_padding_mask)\n        attn2 = self.dropout2(attn2, training = training)\n        out2 = self.layer_norm2(attn2 + out1)\n        \n        # ffn_output, out3.shape: (batch_size, target_seq_len, d_model)\n        ffn_output = self.ffn(out2)\n        ffn_output = self.dropout3(ffn_output, training=training)\n        out3 = self.layer_norm3(ffn_output + out2)\n        \n        return out3, attn_weights1, attn_weights2\n\n#测试一下\nsample_decoder_layer = DecoderLayer(512, 8, 2048)\nsample_decoder_input = tf.random.uniform((64, 60, 512))\nsample_decoder_output, sample_decoder_attn_weights1, sample_decoder_attn_weights2 = sample_decoder_layer(\n    sample_decoder_input, sample_output, False, None, None)\n\nprint(sample_decoder_output.shape)\nprint(sample_decoder_attn_weights1.shape)  #最后一维60是和x的维度一致的\nprint(sample_decoder_attn_weights2.shape) #最后一维60是和x的维度相关的\n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:32:09.062196Z","iopub.execute_input":"2021-08-02T08:32:09.062601Z","iopub.status.idle":"2021-08-02T08:32:09.160919Z","shell.execute_reply.started":"2021-08-02T08:32:09.062567Z","shell.execute_reply":"2021-08-02T08:32:09.159658Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"(64, 60, 512)\n(64, 8, 60, 60)\n(64, 8, 60, 50)\n","output_type":"stream"}]},{"cell_type":"code","source":"#我们多堆建几个EncoderLayer就是我们的EncoderModel\nclass EncoderModel(keras.layers.Layer):\n    def __init__(self, num_layers, input_vocab_size, max_length,\n                 d_model, num_heads, dff, rate=0.1):\n        super(EncoderModel, self).__init__()\n        self.d_model = d_model\n        #这是layers数目\n        self.num_layers = num_layers\n        self.max_length = max_length\n        \n        #构建embedding层\n        self.embedding = keras.layers.Embedding(input_vocab_size,\n                                                self.d_model)\n        # position_embedding.shape: (1, max_length, d_model)\n        self.position_embedding = get_position_embedding(max_length,\n                                                         self.d_model)\n        \n        self.dropout = keras.layers.Dropout(rate)\n        self.encoder_layers = [\n            EncoderLayer(d_model, num_heads, dff, rate)\n            for _ in range(self.num_layers)]\n        \n    \n    def call(self, x, training, encoder_padding_mask):\n        # x.shape: (batch_size, input_seq_len)\n        input_seq_len = tf.shape(x)[1]\n        tf.debugging.assert_less_equal(\n            input_seq_len, self.max_length,\n            \"input_seq_len should be less or equal to self.max_length\")\n        \n        # x.shape: (batch_size, input_seq_len, d_model)\n        x = self.embedding(x)\n        #x做缩放，是值在0到d_model之间\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        #因为x长度比position_embedding可能要小，因此embedding切片后和x相加\n        x += self.position_embedding[:, :input_seq_len, :]\n        \n        x = self.dropout(x, training = training)\n        \n        #得到的x不断作为下一层的输入\n        for i in range(self.num_layers):\n            x = self.encoder_layers[i](x, training,\n                                       encoder_padding_mask)\n        #x最终shape如下\n        # x.shape: (batch_size, input_seq_len, d_model)\n        return x\n\n#测试\nsample_encoder_model = EncoderModel(2, 8500, max_length,\n                                    512, 8, 2048)\nsample_encoder_model_input = tf.random.uniform((64, 37))\nsample_encoder_model_output = sample_encoder_model(\n    sample_encoder_model_input, False, encoder_padding_mask = None)\nprint(sample_encoder_model_output.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:42:50.131433Z","iopub.execute_input":"2021-08-02T08:42:50.131813Z","iopub.status.idle":"2021-08-02T08:42:50.327882Z","shell.execute_reply.started":"2021-08-02T08:42:50.131781Z","shell.execute_reply":"2021-08-02T08:42:50.326602Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"(40, 512)\n(40, 256)\n(40, 256)\n(40, 512)\n(64, 37, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"#和encodermodel类似\nclass DecoderModel(keras.layers.Layer):\n    def __init__(self, num_layers, target_vocab_size, max_length,\n                 d_model, num_heads, dff, rate=0.1):\n        super(DecoderModel, self).__init__()\n        self.num_layers = num_layers\n        self.max_length = max_length\n        self.d_model = d_model\n        \n        self.embedding = keras.layers.Embedding(target_vocab_size,\n                                                d_model)\n        self.position_embedding = get_position_embedding(max_length,\n                                                         d_model)\n        \n        self.dropout = keras.layers.Dropout(rate)\n        self.decoder_layers = [\n            DecoderLayer(d_model, num_heads, dff, rate)\n            for _ in range(self.num_layers)]\n        \n    \n    def call(self, x, encoding_outputs, training,\n             decoder_mask, encoder_decoder_padding_mask):\n        # x.shape: (batch_size, output_seq_len)\n        output_seq_len = tf.shape(x)[1]\n        #如果要输出的商都超出了max_length，就报错\n        tf.debugging.assert_less_equal(\n            output_seq_len, self.max_length,\n            \"output_seq_len should be less or equal to self.max_length\")\n        \n        #attention_weights都是由decoder layer返回，把它保存下来\n        attention_weights = {}\n        \n        # x.shape: (batch_size, output_seq_len, d_model)\n        x = self.embedding(x)\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        x += self.position_embedding[:, :output_seq_len, :]\n        \n        x = self.dropout(x, training = training)\n        \n        for i in range(self.num_layers):\n            #attn1,attn2分别是两个attention\n            x, attn1, attn2 = self.decoder_layers[i](\n                x, encoding_outputs, training,\n                decoder_mask, encoder_decoder_padding_mask)\n            attention_weights[\n                'decoder_layer{}_att1'.format(i+1)] = attn1\n            attention_weights[\n                'decoder_layer{}_att2'.format(i+1)] = attn2\n        # x.shape: (batch_size, output_seq_len, d_model)\n        return x, attention_weights\n\nsample_decoder_model = DecoderModel(2, 8000, max_length,\n                                    512, 8, 2048)\n#测试\nsample_decoder_model_input = tf.random.uniform((64, 35))\nsample_decoder_model_output, sample_decoder_model_att \\\n= sample_decoder_model(\n    sample_decoder_model_input,\n    sample_encoder_model_output,#注意这里是encoder的output\n    training = False, decoder_mask = None,\n    encoder_decoder_padding_mask = None)\n\nprint(sample_decoder_model_output.shape)\n# for key in sample_decoder_model_att:\n#     print(sample_decoder_model_att[key].shape)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-08-02T08:52:00.208184Z","iopub.execute_input":"2021-08-02T08:52:00.208667Z","iopub.status.idle":"2021-08-02T08:52:00.450808Z","shell.execute_reply.started":"2021-08-02T08:52:00.208632Z","shell.execute_reply":"2021-08-02T08:52:00.448858Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"(40, 512)\n(40, 256)\n(40, 256)\n(40, 512)\n(64, 35, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Transformer(keras.Model):\n    def __init__(self, num_layers, input_vocab_size, target_vocab_size,\n                 max_length, d_model, num_heads, dff, rate=0.1):\n        super(Transformer, self).__init__()\n        \n        self.encoder_model = EncoderModel(\n            num_layers, input_vocab_size, max_length,\n            d_model, num_heads, dff, rate)\n        \n        self.decoder_model = DecoderModel(\n            num_layers, target_vocab_size, max_length,\n            d_model, num_heads, dff, rate)\n        \n        self.final_layer = keras.layers.Dense(target_vocab_size)\n    \n    def call(self, inp, tar, training, encoder_padding_mask,\n             decoder_mask, encoder_decoder_padding_mask):\n        # encoding_outputs.shape: (batch_size, input_seq_len, d_model)\n        encoding_outputs = self.encoder_model(\n            inp, training, encoder_padding_mask)\n        \n        # decoding_outputs.shape: (batch_size, output_seq_len, d_model)\n        decoding_outputs, attention_weights = self.decoder_model(\n            tar, encoding_outputs, training,\n            decoder_mask, encoder_decoder_padding_mask)\n        \n        # predictions.shape: (batch_size, output_seq_len, target_vocab_size)\n        predictions = self.final_layer(decoding_outputs)\n        \n        return predictions, attention_weights\n\n#测试\nsample_transformer = Transformer(2, 8500, 8000, max_length,\n                                 512, 8, 2048, rate = 0.1)\ntemp_input = tf.random.uniform((64, 26))\ntemp_target = tf.random.uniform((64, 31))\n\n#得到输出\npredictions, attention_weights = sample_transformer(\n    temp_input, temp_target, training = False,\n    encoder_padding_mask = None,\n    decoder_mask = None,\n    encoder_decoder_padding_mask = None)\n#输出shape\nprint(predictions.shape)\nprint('-'*50)\n#attention_weights 的shape打印\nfor key in attention_weights:\n    print(key, attention_weights[key].shape)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:54:20.290883Z","iopub.execute_input":"2021-08-02T08:54:20.291398Z","iopub.status.idle":"2021-08-02T08:54:20.686680Z","shell.execute_reply.started":"2021-08-02T08:54:20.291310Z","shell.execute_reply":"2021-08-02T08:54:20.685625Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"(40, 512)\n(40, 256)\n(40, 256)\n(40, 512)\n(40, 512)\n(40, 256)\n(40, 256)\n(40, 512)\n(64, 31, 8000)\n--------------------------------------------------\ndecoder_layer1_att1 (64, 8, 31, 31)\ndecoder_layer1_att2 (64, 8, 31, 26)\ndecoder_layer2_att1 (64, 8, 31, 31)\ndecoder_layer2_att2 (64, 8, 31, 26)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1. initializes model.\n# 2. define loss, optimizer, learning_rate schedule\n# 3. train_step\n# 4. train process","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:19.326993Z","iopub.execute_input":"2021-08-02T06:36:19.327552Z","iopub.status.idle":"2021-08-02T06:36:19.334203Z","shell.execute_reply.started":"2021-08-02T06:36:19.327488Z","shell.execute_reply":"2021-08-02T06:36:19.332613Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"max_length","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:57:13.267583Z","iopub.execute_input":"2021-08-02T08:57:13.267949Z","iopub.status.idle":"2021-08-02T08:57:13.277029Z","shell.execute_reply.started":"2021-08-02T08:57:13.267915Z","shell.execute_reply":"2021-08-02T08:57:13.275543Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"40"},"metadata":{}}]},{"cell_type":"code","source":"num_layers = 4\nd_model = 128\ndff = 512\nnum_heads = 8\n#加2是因为最后两个位置是start和end\ninput_vocab_size = pt_tokenizer.vocab_size + 2\ntarget_vocab_size = en_tokenizer.vocab_size + 2\n\ndropout_rate = 0.1\n\ntransformer = Transformer(num_layers,\n                          input_vocab_size,\n                          target_vocab_size,\n                          max_length,\n                          d_model, num_heads, dff, dropout_rate)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:19.336781Z","iopub.execute_input":"2021-08-02T06:36:19.337671Z","iopub.status.idle":"2021-08-02T06:36:19.481666Z","shell.execute_reply.started":"2021-08-02T06:36:19.337618Z","shell.execute_reply":"2021-08-02T06:36:19.480189Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"(40, 128)\n(40, 64)\n(40, 64)\n(40, 128)\n(40, 128)\n(40, 64)\n(40, 64)\n(40, 128)\n","output_type":"stream"}]},{"cell_type":"code","source":"#学习率变化，是先增后减，因为前期可以快点，后期模型比较好，就要慢点\n# lrate = (d_model ** -0.5) * min(step_num ** (-0.5),\n#                                 step_num * warm_up_steps **(-1.5))\n#自定义的学习率调整设计实现\n#这里的公式看这里 https://tensorflow.google.cn/tutorials/text/transformer\nclass CustomizedSchedule(\n    keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, d_model, warmup_steps = 4000):\n        super(CustomizedSchedule, self).__init__()\n        \n        self.d_model = tf.cast(d_model, tf.float32)\n        self.warmup_steps = warmup_steps\n    \n    def __call__(self, step):\n        arg1 = tf.math.rsqrt(step)\n        arg2 = step * (self.warmup_steps ** (-1.5))\n        \n        arg3 = tf.math.rsqrt(self.d_model)\n        \n        return arg3 * tf.math.minimum(arg1, arg2)\n    \nlearning_rate = CustomizedSchedule(d_model)\noptimizer = keras.optimizers.Adam(learning_rate,\n                                  beta_1 = 0.9,\n                                  beta_2 = 0.98,\n                                  epsilon = 1e-9)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:19.483764Z","iopub.execute_input":"2021-08-02T06:36:19.484269Z","iopub.status.idle":"2021-08-02T06:36:19.495860Z","shell.execute_reply.started":"2021-08-02T06:36:19.484219Z","shell.execute_reply":"2021-08-02T06:36:19.494305Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"temp_learning_rate_schedule = CustomizedSchedule(d_model)\n#下面是学习率的设计图\nplt.plot(\n    temp_learning_rate_schedule(\n        tf.range(40000, dtype=tf.float32)))\nplt.ylabel(\"Leraning rate\")\nplt.xlabel(\"Train step\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:19.498015Z","iopub.execute_input":"2021-08-02T06:36:19.498742Z","iopub.status.idle":"2021-08-02T06:36:19.709112Z","shell.execute_reply.started":"2021-08-02T06:36:19.498694Z","shell.execute_reply":"2021-08-02T06:36:19.708028Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 0, 'Train step')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"loss_object = keras.losses.SparseCategoricalCrossentropy(\n    from_logits = True, reduction = 'none')\n\ndef loss_function(real, pred):\n    #损失做了掩码处理，是padding的地方不计算损失\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n    \n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n    \n    return tf.reduce_mean(loss_)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:19.711634Z","iopub.execute_input":"2021-08-02T06:36:19.712068Z","iopub.status.idle":"2021-08-02T06:36:19.720680Z","shell.execute_reply.started":"2021-08-02T06:36:19.712011Z","shell.execute_reply":"2021-08-02T06:36:19.718616Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def create_masks(inp, tar):\n    \"\"\"\n    Encoder:\n      - encoder_padding_mask (self attention of EncoderLayer)\n      对于encoder中padding值没作用，所以无需attention\n    Decoder:\n      - look_ahead_mask (self attention of DecoderLayer)\n      target位置上的词不能看到之后的词，因为之后的词没预测出来\n      - encoder_decoder_padding_mask (encoder-decoder attention of DecoderLayer)\n      decoder不应该到encoder的padding上去花费精力\n      - decoder_padding_mask (self attention of DecoderLayer)\n      decoder也有padding，所以mask掉\n    \"\"\"\n    encoder_padding_mask = create_padding_mask(inp)\n    encoder_decoder_padding_mask = create_padding_mask(inp)\n    \n    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n    decoder_padding_mask = create_padding_mask(tar)\n    decoder_mask = tf.maximum(decoder_padding_mask,\n                              look_ahead_mask)\n    \n    print( encoder_padding_mask.shape )\n    print( encoder_decoder_padding_mask.shape )\n    print( look_ahead_mask.shape )\n    print( decoder_padding_mask.shape )\n    print( decoder_mask.shape )\n\n    \n    return encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:19.722459Z","iopub.execute_input":"2021-08-02T06:36:19.723121Z","iopub.status.idle":"2021-08-02T06:36:19.734469Z","shell.execute_reply.started":"2021-08-02T06:36:19.723075Z","shell.execute_reply":"2021-08-02T06:36:19.733269Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"temp_inp, temp_tar = iter(train_dataset.take(1)).next()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:19.736188Z","iopub.execute_input":"2021-08-02T06:36:19.736802Z","iopub.status.idle":"2021-08-02T06:36:36.956538Z","shell.execute_reply.started":"2021-08-02T06:36:19.736753Z","shell.execute_reply":"2021-08-02T06:36:36.955354Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print(temp_inp.shape)\nprint(temp_tar.shape)\ncreate_masks(temp_inp, temp_tar)\n#样本大小是64，不足的补齐35，或者39\n#最后是(64, 1, 39, 39)原因是既不关注前面的padding，也不关注后面的单词","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:36.958385Z","iopub.execute_input":"2021-08-02T06:36:36.958819Z","iopub.status.idle":"2021-08-02T06:36:36.986390Z","shell.execute_reply.started":"2021-08-02T06:36:36.958772Z","shell.execute_reply":"2021-08-02T06:36:36.984998Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"(64, 40)\n(64, 36)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(<tf.Tensor: shape=(64, 1, 1, 40), dtype=float32, numpy=\n array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        ...,\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n <tf.Tensor: shape=(64, 1, 36, 36), dtype=float32, numpy=\n array([[[[0., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          ...,\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          ...,\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          ...,\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        ...,\n \n \n        [[[0., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          ...,\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          ...,\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 1., 1., ..., 1., 1., 1.],\n          [0., 0., 1., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          ...,\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.],\n          [0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>,\n <tf.Tensor: shape=(64, 1, 1, 40), dtype=float32, numpy=\n array([[[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        ...,\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]],\n \n \n        [[[0., 0., 0., ..., 1., 1., 1.]]]], dtype=float32)>)"},"metadata":{}}]},{"cell_type":"code","source":"train_loss = keras.metrics.Mean(name = 'train_loss')\ntrain_accuracy = keras.metrics.SparseCategoricalAccuracy(\n    name = 'train_accuracy')\n\n@tf.function\ndef train_step(inp, tar):\n    tar_inp  = tar[:, :-1]  #没带end\n    tar_real = tar[:, 1:]   #没有start\n    \n    encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask \\\n    = create_masks(inp, tar_inp)\n    \n    with tf.GradientTape() as tape:\n        predictions, _ = transformer(inp, tar_inp, True,\n                                     encoder_padding_mask,\n                                     decoder_mask,\n                                     encoder_decoder_padding_mask)\n        loss = loss_function(tar_real, predictions)\n    \n    gradients = tape.gradient(loss, transformer.trainable_variables)\n    optimizer.apply_gradients(\n        zip(gradients, transformer.trainable_variables))\n    train_loss(loss)\n    train_accuracy(tar_real, predictions)\n#一个epochs接近90秒\nepochs = 20\nfor epoch in range(epochs):\n    start = time.time()\n    #reset后就会从零开始累计\n    train_loss.reset_states()\n    train_accuracy.reset_states()\n    \n    for (batch, (inp, tar)) in enumerate(train_dataset):\n        train_step(inp, tar)\n        if batch % 100 == 0:\n            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n                epoch + 1, batch, train_loss.result(),\n                train_accuracy.result()))\n    \n    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n        epoch + 1, train_loss.result(), train_accuracy.result()))\n    print('Time take for 1 epoch: {} secs\\n'.format(\n        time.time() - start))\n\n#loss是一个正常的指标，accuracy只是机器翻译的一个参考指标，可以看趋势\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:36:36.988531Z","iopub.execute_input":"2021-08-02T06:36:36.988990Z","iopub.status.idle":"2021-08-02T07:17:04.809180Z","shell.execute_reply.started":"2021-08-02T06:36:36.988940Z","shell.execute_reply":"2021-08-02T07:17:04.807828Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"(64, 1, 1, 38)\n(64, 1, 1, 38)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\nEpoch 1 Batch 0 Loss 4.1451 Accuracy 0.0000\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(39, 39)\n(64, 1, 1, 39)\n(64, 1, 39, 39)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(39, 39)\n(64, 1, 1, 39)\n(64, 1, 39, 39)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(39, 39)\n(64, 1, 1, 39)\n(64, 1, 39, 39)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(39, 39)\n(64, 1, 1, 39)\n(64, 1, 39, 39)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(39, 39)\n(64, 1, 1, 39)\n(64, 1, 39, 39)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(39, 39)\n(64, 1, 1, 39)\n(64, 1, 39, 39)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\nEpoch 1 Batch 100 Loss 4.1901 Accuracy 0.0163\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 1, 1, 31)\n(64, 1, 1, 31)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\nEpoch 1 Batch 200 Loss 4.0840 Accuracy 0.0216\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(39, 39)\n(64, 1, 1, 39)\n(64, 1, 39, 39)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(39, 39)\n(64, 1, 1, 39)\n(64, 1, 39, 39)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\nEpoch 1 Batch 300 Loss 3.9213 Accuracy 0.0234\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\nEpoch 1 Batch 400 Loss 3.7391 Accuracy 0.0300\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\nEpoch 1 Batch 500 Loss 3.5915 Accuracy 0.0365\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\nEpoch 1 Batch 600 Loss 3.4780 Accuracy 0.0434\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\nEpoch 1 Batch 700 Loss 3.3693 Accuracy 0.0506\n(31, 1, 1, 37)\n(31, 1, 1, 37)\n(35, 35)\n(31, 1, 1, 35)\n(31, 1, 35, 35)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\nEpoch 1 Loss 3.3670 Accuracy 0.0507\nTime take for 1 epoch: 434.73859548568726 secs\n\nEpoch 2 Batch 0 Loss 2.3943 Accuracy 0.0958\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\nEpoch 2 Batch 100 Loss 2.5488 Accuracy 0.1046\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(29, 29)\n(64, 1, 1, 29)\n(64, 1, 29, 29)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\nEpoch 2 Batch 200 Loss 2.4968 Accuracy 0.1088\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\nEpoch 2 Batch 300 Loss 2.4602 Accuracy 0.1120\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(34, 34)\n(64, 1, 1, 34)\n(64, 1, 34, 34)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(29, 29)\n(64, 1, 1, 29)\n(64, 1, 29, 29)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\nEpoch 2 Batch 400 Loss 2.4355 Accuracy 0.1154\nEpoch 2 Batch 500 Loss 2.4070 Accuracy 0.1182\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(30, 30)\n(64, 1, 1, 30)\n(64, 1, 30, 30)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\nEpoch 2 Batch 600 Loss 2.3847 Accuracy 0.1207\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\nEpoch 2 Batch 700 Loss 2.3672 Accuracy 0.1233\n(31, 1, 1, 38)\n(31, 1, 1, 38)\n(39, 39)\n(31, 1, 1, 39)\n(31, 1, 39, 39)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\nEpoch 2 Loss 2.3669 Accuracy 0.1233\nTime take for 1 epoch: 185.66297888755798 secs\n\nEpoch 3 Batch 0 Loss 2.2000 Accuracy 0.1324\nEpoch 3 Batch 100 Loss 2.1760 Accuracy 0.1426\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\nEpoch 3 Batch 200 Loss 2.1668 Accuracy 0.1438\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(30, 30)\n(64, 1, 1, 30)\n(64, 1, 30, 30)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\nEpoch 3 Batch 300 Loss 2.1520 Accuracy 0.1446\nEpoch 3 Batch 400 Loss 2.1403 Accuracy 0.1457\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(27, 27)\n(64, 1, 1, 27)\n(64, 1, 27, 27)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 1, 1, 40)\n(64, 1, 1, 40)\n(30, 30)\n(64, 1, 1, 30)\n(64, 1, 30, 30)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 40, 128)\n--------------------------------------------------\n(64, 40, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\nEpoch 3 Batch 500 Loss 2.1344 Accuracy 0.1469\nEpoch 3 Batch 600 Loss 2.1264 Accuracy 0.1481\nEpoch 3 Batch 700 Loss 2.1142 Accuracy 0.1493\nEpoch 3 Loss 2.1143 Accuracy 0.1493\nTime take for 1 epoch: 107.88736939430237 secs\n\nEpoch 4 Batch 0 Loss 1.9272 Accuracy 0.1526\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(30, 30)\n(64, 1, 1, 30)\n(64, 1, 30, 30)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\nEpoch 4 Batch 100 Loss 1.9618 Accuracy 0.1616\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\nEpoch 4 Batch 200 Loss 1.9550 Accuracy 0.1639\n(64, 1, 1, 37)\n(64, 1, 1, 37)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\nEpoch 4 Batch 300 Loss 1.9496 Accuracy 0.1659\n(64, 1, 1, 31)\n(64, 1, 1, 31)\n(35, 35)\n(64, 1, 1, 35)\n(64, 1, 35, 35)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\nEpoch 4 Batch 400 Loss 1.9343 Accuracy 0.1681\nEpoch 4 Batch 500 Loss 1.9226 Accuracy 0.1704\nEpoch 4 Batch 600 Loss 1.9081 Accuracy 0.1724\nEpoch 4 Batch 700 Loss 1.8930 Accuracy 0.1743\n(31, 1, 1, 39)\n(31, 1, 1, 39)\n(37, 37)\n(31, 1, 1, 37)\n(31, 1, 37, 37)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\nEpoch 4 Loss 1.8928 Accuracy 0.1743\nTime take for 1 epoch: 120.45684027671814 secs\n\nEpoch 5 Batch 0 Loss 1.7727 Accuracy 0.1959\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(28, 28)\n(64, 1, 1, 28)\n(64, 1, 28, 28)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(29, 29)\n(64, 1, 1, 29)\n(64, 1, 29, 29)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\nEpoch 5 Batch 100 Loss 1.7341 Accuracy 0.1929\nEpoch 5 Batch 200 Loss 1.7243 Accuracy 0.1946\nEpoch 5 Batch 300 Loss 1.7131 Accuracy 0.1962\nEpoch 5 Batch 400 Loss 1.6955 Accuracy 0.1980\nEpoch 5 Batch 500 Loss 1.6854 Accuracy 0.1994\nEpoch 5 Batch 600 Loss 1.6788 Accuracy 0.2007\n(64, 1, 1, 31)\n(64, 1, 1, 31)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\nEpoch 5 Batch 700 Loss 1.6682 Accuracy 0.2021\n(31, 1, 1, 32)\n(31, 1, 1, 32)\n(33, 33)\n(31, 1, 1, 33)\n(31, 1, 33, 33)\n(31, 32, 128)\n--------------------------------------------------\n(31, 32, 128)\n(31, 32, 128)\n--------------------------------------------------\n(31, 32, 128)\n(31, 32, 128)\n--------------------------------------------------\n(31, 32, 128)\n(31, 32, 128)\n--------------------------------------------------\n(31, 32, 128)\n(31, 33, 128)\n--------------------------------------------------\n(31, 33, 128)\n(31, 33, 128)\n--------------------------------------------------\n(31, 33, 128)\n(31, 33, 128)\n--------------------------------------------------\n(31, 33, 128)\n(31, 33, 128)\n--------------------------------------------------\n(31, 33, 128)\n(31, 33, 128)\n--------------------------------------------------\n(31, 33, 128)\n(31, 33, 128)\n--------------------------------------------------\n(31, 33, 128)\n(31, 33, 128)\n--------------------------------------------------\n(31, 33, 128)\n(31, 33, 128)\n--------------------------------------------------\n(31, 33, 128)\nEpoch 5 Loss 1.6680 Accuracy 0.2021\nTime take for 1 epoch: 109.1726188659668 secs\n\nEpoch 6 Batch 0 Loss 1.3933 Accuracy 0.2031\n(64, 1, 1, 34)\n(64, 1, 1, 34)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 34, 128)\n--------------------------------------------------\n(64, 34, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\nEpoch 6 Batch 100 Loss 1.5101 Accuracy 0.2183\nEpoch 6 Batch 200 Loss 1.4986 Accuracy 0.2185\nEpoch 6 Batch 300 Loss 1.4993 Accuracy 0.2198\nEpoch 6 Batch 400 Loss 1.4929 Accuracy 0.2213\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\nEpoch 6 Batch 500 Loss 1.4888 Accuracy 0.2229\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\nEpoch 6 Batch 600 Loss 1.4833 Accuracy 0.2239\nEpoch 6 Batch 700 Loss 1.4740 Accuracy 0.2248\n(31, 1, 1, 35)\n(31, 1, 1, 35)\n(31, 31)\n(31, 1, 1, 31)\n(31, 1, 31, 31)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 31, 128)\n--------------------------------------------------\n(31, 31, 128)\n(31, 31, 128)\n--------------------------------------------------\n(31, 31, 128)\n(31, 31, 128)\n--------------------------------------------------\n(31, 31, 128)\n(31, 31, 128)\n--------------------------------------------------\n(31, 31, 128)\n(31, 31, 128)\n--------------------------------------------------\n(31, 31, 128)\n(31, 31, 128)\n--------------------------------------------------\n(31, 31, 128)\n(31, 31, 128)\n--------------------------------------------------\n(31, 31, 128)\n(31, 31, 128)\n--------------------------------------------------\n(31, 31, 128)\nEpoch 6 Loss 1.4741 Accuracy 0.2249\nTime take for 1 epoch: 117.3853223323822 secs\n\nEpoch 7 Batch 0 Loss 1.2899 Accuracy 0.2404\nEpoch 7 Batch 100 Loss 1.3194 Accuracy 0.2434\nEpoch 7 Batch 200 Loss 1.3157 Accuracy 0.2440\nEpoch 7 Batch 300 Loss 1.3107 Accuracy 0.2440\n(64, 1, 1, 31)\n(64, 1, 1, 31)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(29, 29)\n(64, 1, 1, 29)\n(64, 1, 29, 29)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\nEpoch 7 Batch 400 Loss 1.3044 Accuracy 0.2451\nEpoch 7 Batch 500 Loss 1.2985 Accuracy 0.2460\n(64, 1, 1, 35)\n(64, 1, 1, 35)\n(30, 30)\n(64, 1, 1, 30)\n(64, 1, 30, 30)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 35, 128)\n--------------------------------------------------\n(64, 35, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\nEpoch 7 Batch 600 Loss 1.2904 Accuracy 0.2462\nEpoch 7 Batch 700 Loss 1.2817 Accuracy 0.2467\n(31, 1, 1, 39)\n(31, 1, 1, 39)\n(34, 34)\n(31, 1, 1, 34)\n(31, 1, 34, 34)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\nEpoch 7 Loss 1.2817 Accuracy 0.2467\nTime take for 1 epoch: 108.0173351764679 secs\n\nEpoch 8 Batch 0 Loss 1.1873 Accuracy 0.2644\nEpoch 8 Batch 100 Loss 1.1345 Accuracy 0.2659\nEpoch 8 Batch 200 Loss 1.1376 Accuracy 0.2645\nEpoch 8 Batch 300 Loss 1.1346 Accuracy 0.2643\nEpoch 8 Batch 400 Loss 1.1299 Accuracy 0.2646\n(64, 1, 1, 30)\n(64, 1, 1, 30)\n(28, 28)\n(64, 1, 1, 28)\n(64, 1, 28, 28)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\n(64, 28, 128)\n--------------------------------------------------\n(64, 28, 128)\nEpoch 8 Batch 500 Loss 1.1271 Accuracy 0.2650\nEpoch 8 Batch 600 Loss 1.1279 Accuracy 0.2655\nEpoch 8 Batch 700 Loss 1.1262 Accuracy 0.2660\n(31, 1, 1, 35)\n(31, 1, 1, 35)\n(39, 39)\n(31, 1, 1, 39)\n(31, 1, 39, 39)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\n(31, 39, 128)\n--------------------------------------------------\n(31, 39, 128)\nEpoch 8 Loss 1.1262 Accuracy 0.2660\nTime take for 1 epoch: 96.50361013412476 secs\n\nEpoch 9 Batch 0 Loss 0.9064 Accuracy 0.2612\n(64, 1, 1, 36)\n(64, 1, 1, 36)\n(29, 29)\n(64, 1, 1, 29)\n(64, 1, 29, 29)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\nEpoch 9 Batch 100 Loss 0.9896 Accuracy 0.2764\nEpoch 9 Batch 200 Loss 0.9979 Accuracy 0.2780\n(64, 1, 1, 30)\n(64, 1, 1, 30)\n(27, 27)\n(64, 1, 1, 27)\n(64, 1, 27, 27)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\n(64, 27, 128)\n--------------------------------------------------\n(64, 27, 128)\nEpoch 9 Batch 300 Loss 1.0091 Accuracy 0.2797\nEpoch 9 Batch 400 Loss 1.0106 Accuracy 0.2808\nEpoch 9 Batch 500 Loss 1.0126 Accuracy 0.2813\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(32, 32)\n(64, 1, 1, 32)\n(64, 1, 32, 32)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 1, 1, 30)\n(64, 1, 1, 30)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\nEpoch 9 Batch 600 Loss 1.0142 Accuracy 0.2808\nEpoch 9 Batch 700 Loss 1.0144 Accuracy 0.2804\nEpoch 9 Loss 1.0142 Accuracy 0.2803\nTime take for 1 epoch: 108.41008996963501 secs\n\nEpoch 10 Batch 0 Loss 0.8089 Accuracy 0.2780\nEpoch 10 Batch 100 Loss 0.9011 Accuracy 0.2939\nEpoch 10 Batch 200 Loss 0.9147 Accuracy 0.2922\nEpoch 10 Batch 300 Loss 0.9184 Accuracy 0.2915\nEpoch 10 Batch 400 Loss 0.9212 Accuracy 0.2909\nEpoch 10 Batch 500 Loss 0.9232 Accuracy 0.2908\nEpoch 10 Batch 600 Loss 0.9257 Accuracy 0.2908\nEpoch 10 Batch 700 Loss 0.9284 Accuracy 0.2908\nEpoch 10 Loss 0.9286 Accuracy 0.2908\nTime take for 1 epoch: 85.48165607452393 secs\n\nEpoch 11 Batch 0 Loss 0.8439 Accuracy 0.3120\nEpoch 11 Batch 100 Loss 0.8308 Accuracy 0.3022\nEpoch 11 Batch 200 Loss 0.8307 Accuracy 0.3000\n(64, 1, 1, 30)\n(64, 1, 1, 30)\n(37, 37)\n(64, 1, 1, 37)\n(64, 1, 37, 37)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\n(64, 37, 128)\n--------------------------------------------------\n(64, 37, 128)\nEpoch 11 Batch 300 Loss 0.8373 Accuracy 0.3002\nEpoch 11 Batch 400 Loss 0.8436 Accuracy 0.3002\nEpoch 11 Batch 500 Loss 0.8467 Accuracy 0.3006\nEpoch 11 Batch 600 Loss 0.8522 Accuracy 0.3000\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(31, 31)\n(64, 1, 1, 31)\n(64, 1, 31, 31)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\nEpoch 11 Batch 700 Loss 0.8578 Accuracy 0.2994\n(31, 1, 1, 38)\n(31, 1, 1, 38)\n(37, 37)\n(31, 1, 1, 37)\n(31, 1, 37, 37)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\n(31, 37, 128)\n--------------------------------------------------\n(31, 37, 128)\nEpoch 11 Loss 0.8579 Accuracy 0.2994\nTime take for 1 epoch: 101.54603004455566 secs\n\nEpoch 12 Batch 0 Loss 0.7427 Accuracy 0.3014\n(64, 1, 1, 31)\n(64, 1, 1, 31)\n(33, 33)\n(64, 1, 1, 33)\n(64, 1, 33, 33)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 31, 128)\n--------------------------------------------------\n(64, 31, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 1, 1, 39)\n(64, 1, 1, 39)\n(29, 29)\n(64, 1, 1, 29)\n(64, 1, 29, 29)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 39, 128)\n--------------------------------------------------\n(64, 39, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 1, 1, 32)\n(64, 1, 1, 32)\n(38, 38)\n(64, 1, 1, 38)\n(64, 1, 38, 38)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 32, 128)\n--------------------------------------------------\n(64, 32, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\nEpoch 12 Batch 100 Loss 0.7808 Accuracy 0.3110\nEpoch 12 Batch 200 Loss 0.7803 Accuracy 0.3088\nEpoch 12 Batch 300 Loss 0.7904 Accuracy 0.3093\nEpoch 12 Batch 400 Loss 0.7918 Accuracy 0.3088\nEpoch 12 Batch 500 Loss 0.7942 Accuracy 0.3077\nEpoch 12 Batch 600 Loss 0.7979 Accuracy 0.3072\nEpoch 12 Batch 700 Loss 0.8024 Accuracy 0.3067\n(31, 1, 1, 38)\n(31, 1, 1, 38)\n(35, 35)\n(31, 1, 1, 35)\n(31, 1, 35, 35)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\nEpoch 12 Loss 0.8025 Accuracy 0.3068\nTime take for 1 epoch: 108.07761287689209 secs\n\nEpoch 13 Batch 0 Loss 0.7500 Accuracy 0.3220\nEpoch 13 Batch 100 Loss 0.7162 Accuracy 0.3161\nEpoch 13 Batch 200 Loss 0.7303 Accuracy 0.3153\nEpoch 13 Batch 300 Loss 0.7394 Accuracy 0.3147\nEpoch 13 Batch 400 Loss 0.7426 Accuracy 0.3151\nEpoch 13 Batch 500 Loss 0.7494 Accuracy 0.3147\n(64, 1, 1, 30)\n(64, 1, 1, 30)\n(36, 36)\n(64, 1, 1, 36)\n(64, 1, 36, 36)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\n(64, 36, 128)\n--------------------------------------------------\n(64, 36, 128)\nEpoch 13 Batch 600 Loss 0.7528 Accuracy 0.3139\nEpoch 13 Batch 700 Loss 0.7563 Accuracy 0.3129\n(31, 1, 1, 38)\n(31, 1, 1, 38)\n(38, 38)\n(31, 1, 1, 38)\n(31, 1, 38, 38)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\nEpoch 13 Loss 0.7564 Accuracy 0.3129\nTime take for 1 epoch: 95.96468424797058 secs\n\nEpoch 14 Batch 0 Loss 0.5495 Accuracy 0.2965\nEpoch 14 Batch 100 Loss 0.6821 Accuracy 0.3248\nEpoch 14 Batch 200 Loss 0.6919 Accuracy 0.3231\nEpoch 14 Batch 300 Loss 0.6978 Accuracy 0.3212\nEpoch 14 Batch 400 Loss 0.7016 Accuracy 0.3204\nEpoch 14 Batch 500 Loss 0.7057 Accuracy 0.3200\nEpoch 14 Batch 600 Loss 0.7110 Accuracy 0.3195\n(64, 1, 1, 38)\n(64, 1, 1, 38)\n(30, 30)\n(64, 1, 1, 30)\n(64, 1, 30, 30)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 38, 128)\n--------------------------------------------------\n(64, 38, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\nEpoch 14 Batch 700 Loss 0.7165 Accuracy 0.3190\n(31, 1, 1, 40)\n(31, 1, 1, 40)\n(35, 35)\n(31, 1, 1, 35)\n(31, 1, 35, 35)\n(31, 40, 128)\n--------------------------------------------------\n(31, 40, 128)\n(31, 40, 128)\n--------------------------------------------------\n(31, 40, 128)\n(31, 40, 128)\n--------------------------------------------------\n(31, 40, 128)\n(31, 40, 128)\n--------------------------------------------------\n(31, 40, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\nEpoch 14 Loss 0.7167 Accuracy 0.3190\nTime take for 1 epoch: 96.62212705612183 secs\n\nEpoch 15 Batch 0 Loss 0.5299 Accuracy 0.3010\nEpoch 15 Batch 100 Loss 0.6520 Accuracy 0.3313\nEpoch 15 Batch 200 Loss 0.6583 Accuracy 0.3286\nEpoch 15 Batch 300 Loss 0.6629 Accuracy 0.3270\n(64, 1, 1, 33)\n(64, 1, 1, 33)\n(29, 29)\n(64, 1, 1, 29)\n(64, 1, 29, 29)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 33, 128)\n--------------------------------------------------\n(64, 33, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\n(64, 29, 128)\n--------------------------------------------------\n(64, 29, 128)\nEpoch 15 Batch 400 Loss 0.6693 Accuracy 0.3267\n(64, 1, 1, 30)\n(64, 1, 1, 30)\n(30, 30)\n(64, 1, 1, 30)\n(64, 1, 30, 30)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\n(64, 30, 128)\n--------------------------------------------------\n(64, 30, 128)\nEpoch 15 Batch 500 Loss 0.6715 Accuracy 0.3261\nEpoch 15 Batch 600 Loss 0.6762 Accuracy 0.3252\nEpoch 15 Batch 700 Loss 0.6811 Accuracy 0.3248\n(31, 1, 1, 38)\n(31, 1, 1, 38)\n(36, 36)\n(31, 1, 1, 36)\n(31, 1, 36, 36)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 36, 128)\n--------------------------------------------------\n(31, 36, 128)\n(31, 36, 128)\n--------------------------------------------------\n(31, 36, 128)\n(31, 36, 128)\n--------------------------------------------------\n(31, 36, 128)\n(31, 36, 128)\n--------------------------------------------------\n(31, 36, 128)\n(31, 36, 128)\n--------------------------------------------------\n(31, 36, 128)\n(31, 36, 128)\n--------------------------------------------------\n(31, 36, 128)\n(31, 36, 128)\n--------------------------------------------------\n(31, 36, 128)\n(31, 36, 128)\n--------------------------------------------------\n(31, 36, 128)\nEpoch 15 Loss 0.6812 Accuracy 0.3248\nTime take for 1 epoch: 106.18081450462341 secs\n\nEpoch 16 Batch 0 Loss 0.5504 Accuracy 0.3406\nEpoch 16 Batch 100 Loss 0.6193 Accuracy 0.3355\nEpoch 16 Batch 200 Loss 0.6235 Accuracy 0.3319\nEpoch 16 Batch 300 Loss 0.6307 Accuracy 0.3313\nEpoch 16 Batch 400 Loss 0.6364 Accuracy 0.3325\nEpoch 16 Batch 500 Loss 0.6414 Accuracy 0.3316\nEpoch 16 Batch 600 Loss 0.6456 Accuracy 0.3305\nEpoch 16 Batch 700 Loss 0.6510 Accuracy 0.3298\n(31, 1, 1, 35)\n(31, 1, 1, 35)\n(34, 34)\n(31, 1, 1, 34)\n(31, 1, 34, 34)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 35, 128)\n--------------------------------------------------\n(31, 35, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\n(31, 34, 128)\n--------------------------------------------------\n(31, 34, 128)\nEpoch 16 Loss 0.6508 Accuracy 0.3297\nTime take for 1 epoch: 91.9936957359314 secs\n\nEpoch 17 Batch 0 Loss 0.6426 Accuracy 0.3630\nEpoch 17 Batch 100 Loss 0.5775 Accuracy 0.3366\nEpoch 17 Batch 200 Loss 0.5908 Accuracy 0.3370\nEpoch 17 Batch 300 Loss 0.5974 Accuracy 0.3350\nEpoch 17 Batch 400 Loss 0.6012 Accuracy 0.3341\nEpoch 17 Batch 500 Loss 0.6071 Accuracy 0.3337\nEpoch 17 Batch 600 Loss 0.6140 Accuracy 0.3337\nEpoch 17 Batch 700 Loss 0.6218 Accuracy 0.3333\nEpoch 17 Loss 0.6219 Accuracy 0.3334\nTime take for 1 epoch: 85.28563261032104 secs\n\nEpoch 18 Batch 0 Loss 0.5507 Accuracy 0.3733\nEpoch 18 Batch 100 Loss 0.5588 Accuracy 0.3420\nEpoch 18 Batch 200 Loss 0.5687 Accuracy 0.3416\nEpoch 18 Batch 300 Loss 0.5734 Accuracy 0.3408\nEpoch 18 Batch 400 Loss 0.5790 Accuracy 0.3394\nEpoch 18 Batch 500 Loss 0.5831 Accuracy 0.3385\nEpoch 18 Batch 600 Loss 0.5908 Accuracy 0.3378\nEpoch 18 Batch 700 Loss 0.5961 Accuracy 0.3373\n(31, 1, 1, 40)\n(31, 1, 1, 40)\n(38, 38)\n(31, 1, 1, 38)\n(31, 1, 38, 38)\n(31, 40, 128)\n--------------------------------------------------\n(31, 40, 128)\n(31, 40, 128)\n--------------------------------------------------\n(31, 40, 128)\n(31, 40, 128)\n--------------------------------------------------\n(31, 40, 128)\n(31, 40, 128)\n--------------------------------------------------\n(31, 40, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\n(31, 38, 128)\n--------------------------------------------------\n(31, 38, 128)\nEpoch 18 Loss 0.5960 Accuracy 0.3372\nTime take for 1 epoch: 91.30433797836304 secs\n\nEpoch 19 Batch 0 Loss 0.5497 Accuracy 0.3511\nEpoch 19 Batch 100 Loss 0.5376 Accuracy 0.3466\nEpoch 19 Batch 200 Loss 0.5451 Accuracy 0.3460\nEpoch 19 Batch 300 Loss 0.5512 Accuracy 0.3437\nEpoch 19 Batch 400 Loss 0.5584 Accuracy 0.3435\nEpoch 19 Batch 500 Loss 0.5627 Accuracy 0.3433\nEpoch 19 Batch 600 Loss 0.5679 Accuracy 0.3423\nEpoch 19 Batch 700 Loss 0.5738 Accuracy 0.3411\n(31, 1, 1, 32)\n(31, 1, 1, 32)\n(30, 30)\n(31, 1, 1, 30)\n(31, 1, 30, 30)\n(31, 32, 128)\n--------------------------------------------------\n(31, 32, 128)\n(31, 32, 128)\n--------------------------------------------------\n(31, 32, 128)\n(31, 32, 128)\n--------------------------------------------------\n(31, 32, 128)\n(31, 32, 128)\n--------------------------------------------------\n(31, 32, 128)\n(31, 30, 128)\n--------------------------------------------------\n(31, 30, 128)\n(31, 30, 128)\n--------------------------------------------------\n(31, 30, 128)\n(31, 30, 128)\n--------------------------------------------------\n(31, 30, 128)\n(31, 30, 128)\n--------------------------------------------------\n(31, 30, 128)\n(31, 30, 128)\n--------------------------------------------------\n(31, 30, 128)\n(31, 30, 128)\n--------------------------------------------------\n(31, 30, 128)\n(31, 30, 128)\n--------------------------------------------------\n(31, 30, 128)\n(31, 30, 128)\n--------------------------------------------------\n(31, 30, 128)\nEpoch 19 Loss 0.5739 Accuracy 0.3411\nTime take for 1 epoch: 92.2586772441864 secs\n\nEpoch 20 Batch 0 Loss 0.5148 Accuracy 0.2889\nEpoch 20 Batch 100 Loss 0.5089 Accuracy 0.3469\nEpoch 20 Batch 200 Loss 0.5226 Accuracy 0.3475\nEpoch 20 Batch 300 Loss 0.5301 Accuracy 0.3468\nEpoch 20 Batch 400 Loss 0.5355 Accuracy 0.3466\nEpoch 20 Batch 500 Loss 0.5423 Accuracy 0.3464\nEpoch 20 Batch 600 Loss 0.5482 Accuracy 0.3458\nEpoch 20 Batch 700 Loss 0.5524 Accuracy 0.3449\nEpoch 20 Loss 0.5526 Accuracy 0.3449\nTime take for 1 epoch: 84.83109641075134 secs\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\neg: A B C D -> E F G H.\nTrain: A B C D, E F G -> F G H\nEval:  A B C D -> E\n       A B C D, E -> F\n       A B C D, E F -> G\n       A B C D, E F G -> H\n类似seq2seq2\n不同的是 transformer可以并行的处理，前后没有依赖，而seq2seq前后有依赖\n\"\"\"\ndef evaluate(inp_sentence):\n    #文本的句子转换为id的句子\n    input_id_sentence = [pt_tokenizer.vocab_size] \\\n    + pt_tokenizer.encode(inp_sentence) + [pt_tokenizer.vocab_size + 1]\n    #transformer转换是两维的，因此转换\n    # encoder_input.shape: (1, input_sentence_length)\n    encoder_input = tf.expand_dims(input_id_sentence, 0)\n    \n    # decoder_input.shape: (1, 1)\n    #我们预测一个词就放入decoder_input，decoder_input给多个就可以预测多个，我们给一个\n    decoder_input = tf.expand_dims([en_tokenizer.vocab_size], 0)\n    \n    for i in range(max_length):\n        #产生mask并传给transformer\n        encoder_padding_mask, decoder_mask, encoder_decoder_padding_mask \\\n        = create_masks(encoder_input, decoder_input)\n        # predictions.shape: (batch_size, output_target_len, target_vocab_size)\n        predictions, attention_weights = transformer(\n            encoder_input,\n            decoder_input,\n            False,\n            encoder_padding_mask,\n            decoder_mask,\n            encoder_decoder_padding_mask)\n        # predictions.shape: (batch_size, target_vocab_size)\n        #我们每次只预测一个，所以是最后一个\n        predictions = predictions[:, -1, :]\n        #预测值就是概率最大的那个的索引\n        predicted_id = tf.cast(tf.argmax(predictions, axis = -1),\n                               tf.int32)\n        #如果等于end id，预测结束\n        if tf.equal(predicted_id, en_tokenizer.vocab_size + 1):\n            return tf.squeeze(decoder_input, axis = 0), attention_weights\n        #如果predicted_id不是end id，添加到新的decoder_input中\n        decoder_input = tf.concat([decoder_input, [predicted_id]],\n                                  axis = -1)\n    return tf.squeeze(decoder_input, axis = 0), attention_weights\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:17:04.815843Z","iopub.execute_input":"2021-08-02T07:17:04.816285Z","iopub.status.idle":"2021-08-02T07:17:04.838781Z","shell.execute_reply.started":"2021-08-02T07:17:04.816232Z","shell.execute_reply":"2021-08-02T07:17:04.837410Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def plot_encoder_decoder_attention(attention, input_sentence,\n                                   result, layer_name):\n    fig = plt.figure(figsize = (16, 8))\n    \n    input_id_sentence = pt_tokenizer.encode(input_sentence)\n    \n    # attention.shape: (num_heads, tar_len, input_len)\n    attention = tf.squeeze(attention[layer_name], axis = 0)\n    \n    for head in range(attention.shape[0]):\n        ax = fig.add_subplot(2, 4, head + 1)\n        \n        ax.matshow(attention[head][:-1, :])\n        \n        fontdict = {'fontsize': 10}\n        \n        ax.set_xticks(range(len(input_id_sentence) + 2))\n        ax.set_yticks(range(len(result)))\n        \n        ax.set_ylim(len(result) - 1.5, -0.5)\n        \n        ax.set_xticklabels(\n            ['<start>'] + [pt_tokenizer.decode([i]) for i in input_id_sentence] + ['<end>'],\n            fontdict = fontdict, rotation = 90)\n        ax.set_yticklabels(\n            [en_tokenizer.decode([i]) for i in result if i < en_tokenizer.vocab_size],\n            fontdict = fontdict)\n        ax.set_xlabel('Head {}'.format(head + 1))\n    plt.tight_layout()\n    plt.show()      ","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:17:04.840571Z","iopub.execute_input":"2021-08-02T07:17:04.841295Z","iopub.status.idle":"2021-08-02T07:17:04.857495Z","shell.execute_reply.started":"2021-08-02T07:17:04.841245Z","shell.execute_reply":"2021-08-02T07:17:04.856026Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def translate(input_sentence, layer_name = ''):\n    result, attention_weights = evaluate(input_sentence)\n    \n    predicted_sentence = en_tokenizer.decode(\n        [i for i in result if i < en_tokenizer.vocab_size])\n    \n    print(\"Input: {}\".format(input_sentence))\n    print(\"Predicted translation: {}\".format(predicted_sentence))\n    \n    if layer_name:\n        plot_encoder_decoder_attention(attention_weights, input_sentence,\n                                       result, layer_name)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:17:04.859580Z","iopub.execute_input":"2021-08-02T07:17:04.860489Z","iopub.status.idle":"2021-08-02T07:17:04.875033Z","shell.execute_reply.started":"2021-08-02T07:17:04.860441Z","shell.execute_reply":"2021-08-02T07:17:04.873408Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"translate('está muito frio aqui.')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:17:04.878720Z","iopub.execute_input":"2021-08-02T07:17:04.879264Z","iopub.status.idle":"2021-08-02T07:17:06.262626Z","shell.execute_reply.started":"2021-08-02T07:17:04.879220Z","shell.execute_reply":"2021-08-02T07:17:06.260644Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"(1, 1, 1, 8)\n(1, 1, 1, 8)\n(1, 1)\n(1, 1, 1, 1)\n(1, 1, 1, 1)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(2, 2)\n(1, 1, 1, 2)\n(1, 1, 2, 2)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(3, 3)\n(1, 1, 1, 3)\n(1, 1, 3, 3)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(4, 4)\n(1, 1, 1, 4)\n(1, 1, 4, 4)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(5, 5)\n(1, 1, 1, 5)\n(1, 1, 5, 5)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(6, 6)\n(1, 1, 1, 6)\n(1, 1, 6, 6)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(7, 7)\n(1, 1, 1, 7)\n(1, 1, 7, 7)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(8, 8)\n(1, 1, 1, 8)\n(1, 1, 8, 8)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\nInput: está muito frio aqui.\nPredicted translation: it 's very cold here .\n","output_type":"stream"}]},{"cell_type":"code","source":"translate('isto é minha vida')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:17:06.264399Z","iopub.execute_input":"2021-08-02T07:17:06.264841Z","iopub.status.idle":"2021-08-02T07:17:07.602937Z","shell.execute_reply.started":"2021-08-02T07:17:06.264796Z","shell.execute_reply":"2021-08-02T07:17:07.601455Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"(1, 1, 1, 6)\n(1, 1, 1, 6)\n(1, 1)\n(1, 1, 1, 1)\n(1, 1, 1, 1)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 1, 6)\n(1, 1, 1, 6)\n(2, 2)\n(1, 1, 1, 2)\n(1, 1, 2, 2)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 1, 1, 6)\n(1, 1, 1, 6)\n(3, 3)\n(1, 1, 1, 3)\n(1, 1, 3, 3)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 1, 1, 6)\n(1, 1, 1, 6)\n(4, 4)\n(1, 1, 1, 4)\n(1, 1, 4, 4)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 1, 1, 6)\n(1, 1, 1, 6)\n(5, 5)\n(1, 1, 1, 5)\n(1, 1, 5, 5)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 1, 1, 6)\n(1, 1, 1, 6)\n(6, 6)\n(1, 1, 1, 6)\n(1, 1, 6, 6)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 1, 1, 6)\n(1, 1, 1, 6)\n(7, 7)\n(1, 1, 1, 7)\n(1, 1, 7, 7)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 1, 1, 6)\n(1, 1, 1, 6)\n(8, 8)\n(1, 1, 1, 8)\n(1, 1, 8, 8)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\nInput: isto é minha vida\nPredicted translation: this is my life-life .\n","output_type":"stream"}]},{"cell_type":"code","source":"translate('você ainda está em casa?')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:17:07.605176Z","iopub.execute_input":"2021-08-02T07:17:07.605931Z","iopub.status.idle":"2021-08-02T07:17:08.907163Z","shell.execute_reply.started":"2021-08-02T07:17:07.605882Z","shell.execute_reply":"2021-08-02T07:17:08.906072Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"(1, 1, 1, 8)\n(1, 1, 1, 8)\n(1, 1)\n(1, 1, 1, 1)\n(1, 1, 1, 1)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(2, 2)\n(1, 1, 1, 2)\n(1, 1, 2, 2)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(3, 3)\n(1, 1, 1, 3)\n(1, 1, 3, 3)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(4, 4)\n(1, 1, 1, 4)\n(1, 1, 4, 4)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(5, 5)\n(1, 1, 1, 5)\n(1, 1, 5, 5)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 1, 1, 8)\n(1, 1, 1, 8)\n(6, 6)\n(1, 1, 1, 6)\n(1, 1, 6, 6)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\nInput: você ainda está em casa?\nPredicted translation: are you still home ?\n","output_type":"stream"}]},{"cell_type":"code","source":"translate('este é o primeiro livro que eu já li')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:17:08.909048Z","iopub.execute_input":"2021-08-02T07:17:08.909542Z","iopub.status.idle":"2021-08-02T07:17:10.814332Z","shell.execute_reply.started":"2021-08-02T07:17:08.909491Z","shell.execute_reply":"2021-08-02T07:17:10.812604Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"(1, 1, 1, 11)\n(1, 1, 1, 11)\n(1, 1)\n(1, 1, 1, 1)\n(1, 1, 1, 1)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(2, 2)\n(1, 1, 1, 2)\n(1, 1, 2, 2)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(3, 3)\n(1, 1, 1, 3)\n(1, 1, 3, 3)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(4, 4)\n(1, 1, 1, 4)\n(1, 1, 4, 4)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(5, 5)\n(1, 1, 1, 5)\n(1, 1, 5, 5)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(6, 6)\n(1, 1, 1, 6)\n(1, 1, 6, 6)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(7, 7)\n(1, 1, 1, 7)\n(1, 1, 7, 7)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(8, 8)\n(1, 1, 1, 8)\n(1, 1, 8, 8)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(9, 9)\n(1, 1, 1, 9)\n(1, 1, 9, 9)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(10, 10)\n(1, 1, 1, 10)\n(1, 1, 10, 10)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(11, 11)\n(1, 1, 1, 11)\n(1, 1, 11, 11)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\nInput: este é o primeiro livro que eu já li\nPredicted translation: this is the first book that i already had .\n","output_type":"stream"}]},{"cell_type":"code","source":"translate('este é o primeiro livro que eu já li',\n          layer_name = 'decoder_layer4_att2')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T07:17:10.817559Z","iopub.execute_input":"2021-08-02T07:17:10.817962Z","iopub.status.idle":"2021-08-02T07:17:13.405799Z","shell.execute_reply.started":"2021-08-02T07:17:10.817927Z","shell.execute_reply":"2021-08-02T07:17:13.402179Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"(1, 1, 1, 11)\n(1, 1, 1, 11)\n(1, 1)\n(1, 1, 1, 1)\n(1, 1, 1, 1)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 128)\n--------------------------------------------------\n(1, 1, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(2, 2)\n(1, 1, 1, 2)\n(1, 1, 2, 2)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 2, 128)\n--------------------------------------------------\n(1, 2, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(3, 3)\n(1, 1, 1, 3)\n(1, 1, 3, 3)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 3, 128)\n--------------------------------------------------\n(1, 3, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(4, 4)\n(1, 1, 1, 4)\n(1, 1, 4, 4)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 4, 128)\n--------------------------------------------------\n(1, 4, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(5, 5)\n(1, 1, 1, 5)\n(1, 1, 5, 5)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 5, 128)\n--------------------------------------------------\n(1, 5, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(6, 6)\n(1, 1, 1, 6)\n(1, 1, 6, 6)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 6, 128)\n--------------------------------------------------\n(1, 6, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(7, 7)\n(1, 1, 1, 7)\n(1, 1, 7, 7)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 7, 128)\n--------------------------------------------------\n(1, 7, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(8, 8)\n(1, 1, 1, 8)\n(1, 1, 8, 8)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 8, 128)\n--------------------------------------------------\n(1, 8, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(9, 9)\n(1, 1, 1, 9)\n(1, 1, 9, 9)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 9, 128)\n--------------------------------------------------\n(1, 9, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(10, 10)\n(1, 1, 1, 10)\n(1, 1, 10, 10)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 10, 128)\n--------------------------------------------------\n(1, 10, 128)\n(1, 1, 1, 11)\n(1, 1, 1, 11)\n(11, 11)\n(1, 1, 1, 11)\n(1, 1, 11, 11)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\n(1, 11, 128)\n--------------------------------------------------\n(1, 11, 128)\nInput: este é o primeiro livro que eu já li\nPredicted translation: this is the first book that i already had .\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-c2f17fa2eab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m translate('este é o primeiro livro que eu já li',\n\u001b[0;32m----> 2\u001b[0;31m           layer_name = 'decoder_layer4_att2')\n\u001b[0m","\u001b[0;32m<ipython-input-49-c1dc5bcd173f>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(input_sentence, layer_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         plot_encoder_decoder_attention(attention_weights, input_sentence,\n\u001b[0;32m---> 12\u001b[0;31m                                        result, layer_name)\n\u001b[0m","\u001b[0;32m<ipython-input-48-047d617e31c3>\u001b[0m in \u001b[0;36mplot_encoder_decoder_attention\u001b[0;34m(attention, input_sentence, result, layer_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m         ax.set_yticklabels(\n\u001b[1;32m     26\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0men_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             fontdict = fontdict)\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Head {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1699\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 1701\u001b[0;31m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     \u001b[0;34m\" set_ticks, does not match\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (11), usually from a call to set_ticks, does not match the number of ticklabels (10)."],"ename":"ValueError","evalue":"The number of FixedLocator locations (11), usually from a call to set_ticks, does not match the number of ticklabels (10).","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1152x576 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}